<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reinforcement Learning Algorithms in Robotics</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
     <style>
        body {
            background-color: #121212;
            color: white;
        }
        .reference-card {
            background-color: #1e1e1e;
            border-radius: 10px;
            padding: 15px;
            text-align: center;
            margin-bottom: 15px;
            height: 100%;
        }
        .reference-card a {
            color: #00bfff;
            text-decoration: none;
        }
        .reference-card a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <div class="container py-4">
        <h1 class="text-center">Reinforcement Learning Algorithms in Robotics</h1>
        <p>Reinforcement Learning (RL) has emerged as a transformative approach for training autonomous agents to perform complex tasks through trial-and-error interactions. In recent years, RL has played a crucial role in robotics, enabling robots to develop adaptive and intelligent behaviors in dynamic and uncertain environments. Unlike previous reviews, this article focuses exclusively on advanced 
            RL approaches applied to robotics over the last five years, providing a comprehensive analysis of the latest innovations.
           <br> 
            This page provides an overview of reinforcement learning (RL) algorithms applied in robotics. 
            Filters allow you to explore algorithms based on specific dates, types, policy updates, and contributions.</p>
        
        <!-- Algorithm Filter -->
        <div class="mb-4">
            <label for="algorithm-select" class="form-label">Filter by Algorithm:</label>
            <select id="algorithm-select" class="form-select">
                <option value="">All Algorithms</option>
                <option value="DDPG">Deep Deterministic Policy Gradient (DDPG)</option>
                <option value="PPO">Proximal Policy Optimization (PPO)</option>
                <option value="A3C">Asynchronous Advantage Actor-Critic (A3C)</option>
                <option value="TD3">Twin Delayed Deep Deterministic Policy Gradient (TD3)</option>
                <option value="SAC">Soft Actor-Critic (SAC)</option>
                <option value="TRPO">Trust Region Policy Optimization (TRPO)</option>
                <option value="MB-MPO">Model-Based Meta-Policy Optimization (MB-MPO)</option>
                <option value="PMB-RL">Probabilistic Model-Based RL</option>
                <option value="GPS">Guided Policy Search</option>
                <option value="AC">Actor-Critic Methods</option>
                <option value="QL">Q-Learning</option>
            </select>
        </div>

        <!-- Filters for Type and Policy Update -->
        <div class="mb-4">
            <label class="form-label">Type:</label><br>
            <div class="form-check form-check-inline">
                <input class="form-check-input" type="checkbox" id="critere1-1" value="Critere1-1">
                <label class="form-check-label" for="critere1-1">Model-based</label>
            </div>
            <div class="form-check form-check-inline">
                <input class="form-check-input" type="checkbox" id="critere1-2" value="Critere1-2">
                <label class="form-check-label" for="critere1-2">Model-free</label>
            </div>
        </div>

        <div class="mb-4">
            <label class="form-label">Policy Update:</label><br>
            <div class="form-check form-check-inline">
                <input class="form-check-input" type="checkbox" id="critere2-1" value="Critere2-1">
                <label class="form-check-label" for="critere2-1">On-Policy</label>
            </div>
            <div class="form-check form-check-inline">
                <input class="form-check-input" type="checkbox" id="critere2-2" value="Critere2-2">
                <label class="form-check-label" for="critere2-2">Off-Policy</label>
            </div>
        </div>

        <!-- Algorithm Contributions -->
        <ul id="list" class="list-group">
            <li class="list-group-item bg-dark text-white" data-algorithm="DDPG" data-id="Critere1-1-Critere2-1">
                <div class="mb-2">
                    <strong>Deep Deterministic Policy Gradient (DDPG)</strong>: 
                    A reinforcement learning technique used in robotic applications to improve path planning, control, and adaptive exploration.  <a href="https://example.com/paper27" target="_blank">[Read more]</a>
                </div>
            </li>
            <li class="list-group-item bg-dark text-white" data-algorithm="DDPG" data-id="Critere1-1-Critere2-1">
           
                <div class="mb-2">
                    <strong>Path planning in dynamic environments</strong> - This study explores DDPG for navigation in changing environments.
                    <a href="https://example.com/paper27" target="_blank">[Read more]</a>
                </div>
            </li>
            <li class="list-group-item bg-dark text-white" data-algorithm="DDPG" data-id="Critere1-1-Critere2-1">
           
                <div class="mb-2">
                    <strong>Enhanced robot path planning</strong> - Utilizing DDPG to optimize routes while avoiding obstacles.
                    <a href="https://example.com/paper28" target="_blank">[Read more]</a>
                </div>
            
            </li>

                <li class="list-group-item bg-dark text-white" data-algorithm="DDPG" data-id="Critere1-1-Critere2-1">
           
                <div class="mb-2">
                    <strong>Grey Wolf Optimizer for control tasks</strong> - Integration of nature-inspired algorithms with DDPG for robot control.
                    <a href="https://example.com/paper29" target="_blank">[Read more]</a>
                </div>
            </li>
                <li class="list-group-item bg-dark text-white" data-algorithm="DDPG" data-id="Critere1-1-Critere2-1">
           
                <div class="mb-2">
                    <strong>Robotic arm control</strong> - Applying DDPG to improve precision and flexibility in robotic arms.
                    <a href="https://example.com/paper30" target="_blank">[Read more]</a>
                </div>
            </li>
                <li class="list-group-item bg-dark text-white" data-algorithm="DDPG" data-id="Critere1-1-Critere2-1">
           
                <div class="mb-2">
                    <strong>Adaptive exploration for biped robots</strong> - Training biped robots using reinforcement learning to improve balance and adaptability.
                    <a href="https://example.com/paper31" target="_blank">[Read more]</a>
                </div>
            </li>
                <li class="list-group-item bg-dark text-white" data-algorithm="DDPG" data-id="Critere1-1-Critere2-1">
           
                <div class="mb-2">
                    <strong>Double critics for navigation</strong> - Enhancing the decision-making process in robotic movement with dual critic networks.
                    <a href="https://example.com/paper32" target="_blank">[Read more]</a>
                </div>
            </li>
            
            <li class="list-group-item bg-dark text-white" data-algorithm="PPO" data-id="Critere1-1-Critere2-2">
                <span>Proximal Policy Optimization (PPO): Digital twin integration [33], UAV path planning [34], Cloth manipulation [35], Obstacle avoidance [36], Robotic assembly [37].</span>
            </li>
            <li class="list-group-item bg-dark text-white" data-algorithm="A3C" data-id="Critere1-1-Critere2-1">
                <span>Asynchronous Advantage Actor-Critic (A3C): Multi-robot logistics [38], Interaction optimization [39].</span>
            </li>
            <li class="list-group-item bg-dark text-white" data-algorithm="TD3" data-id="Critere1-2-Critere2-1">
                <span>Twin Delayed Deep Deterministic Policy Gradient (TD3): Enhanced action exploration [40], Adaptive navigation [41], Environment perception [42].</span>
            </li>
            <li class="list-group-item bg-dark text-white" data-algorithm="SAC" data-id="Critere1-2-Critere2-2">
                <span>Soft Actor-Critic (SAC): Terrain adaptability [31], Fuzzy control for UUVs [43], Discrete SAC for vascular robots [44], Multi-robot coordination [45], Hindsight replay for manipulators [46], Risk-sensitive navigation [47].</span>
            </li>
            <li class="list-group-item bg-dark text-white" data-algorithm="TRPO" data-id="Critere1-1-Critere2-2">
                <span>Trust Region Policy Optimization (TRPO): Off-policy TRPO [48].</span>
            </li>
            <li class="list-group-item bg-dark text-white" data-algorithm="MB-MPO" data-id="Critere1-2-Critere2-1">
                <span>Model-Based Meta-Policy Optimization (MB-MPO): Probabilistic model-based meta-RL [49].</span>
            </li>
            <li class="list-group-item bg-dark text-white" data-algorithm="PMB-RL" data-id="Critere1-2-Critere2-2">
                <span>Probabilistic Model-Based RL: Dropout uncertainty for practical RL [50].</span>
            </li>
            <li class="list-group-item bg-dark text-white" data-algorithm="GPS" data-id="Critere1-1-Critere2-1">
                <span>Guided Policy Search: Global RL for mobile robots [51], Uncertainty-aware optimization [52], Prediction-guided RL [53].</span>
            </li>
            <li class="list-group-item bg-dark text-white" data-algorithm="AC" data-id="Critere1-1-Critere2-2">
                <span>Actor-Critic Methods: Expert-guided policies [54], Attention-based motion planning [55], Multi-agent efficiency [56].</span>
            </li>
            <li class="list-group-item bg-dark text-white" data-algorithm="QL" data-id="Critere1-2-Critere2-2">
                <span>Q-Learning: Path planning [57], Digital twin systems [58], Constraints-penalized offline RL [59].</span>
            </li>
        </ul>

        <script>
            $(document).ready(function() {
                // Filter function
                function filterList() {
                    var selectedAlgorithm = $('#algorithm-select').val();
                    var selectedCritere1 = $('input[name="critere1"]:checked').map(function() {
                        return this.value;
                    }).get();
                    var selectedCritere2 = $('input[name="critere2"]:checked').map(function() {
                        return this.value;
                    }).get();

                    $('#list li').each(function() {
                        var algorithmMatch = selectedAlgorithm === "" || $(this).data('algorithm') === selectedAlgorithm;
                        var critere1Match = selectedCritere1.length === 0 || selectedCritere1.some(function(crit) {
                            return $(this).data('id').includes(crit);
                        }.bind(this));
                        var critere2Match = selectedCritere2.length === 0 || selectedCritere2.some(function(crit) {
                            return $(this).data('id').includes(crit);
                        }.bind(this));

                        if (algorithmMatch && critere1Match && critere2Match) {
                            $(this).show();
                        } else {
                            $(this).hide();
                        }
                    });
                }

                // Event listeners for filters
                $('#algorithm-select').on('change', filterList);
                $('input[name="critere1"], input[name="critere2"]').on('change', filterList);

                // Initial filter execution
                filterList();
            });
        </script>
    </div>
</body>
</html>
