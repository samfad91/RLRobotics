<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reinforcement Learning Algorithms in Robotics</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
    <style>
        body {
            color: white;
            margin: 0;
            padding: 0;
        }
    
      
        body::before {
            content: "";
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-image: url('back.png');
            background-size: 85%;
            background-position: center;
            background-repeat: no-repeat;
            background-attachment: fixed;
            opacity: 0.5;
            z-index: -1;
        }
        .stats-icon {
    width: 80px;
    height: 80px;
    border-radius: 10px;
    margin: 20px;
}
        .reference-card {
            background-color: #1e1e1e;
            border-radius: 10px;
            padding: 15px;
            text-align: center;
            margin-bottom: 15px;
            margin-left: 8px;
            margin-right: 8px;
            height: 100%;
        }
        .filterC {
            position: sticky;
            top: 10px; /* Distance from the top when scrolling */
            bottom: 10px;
            background-color: rgb(121, 109, 109);
            color: white;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
           
        }
        .desc {
            background-color: rgb(121, 109, 109);
            color: white;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 15px;
        }
        .reference-card a {
            color: #00bfff;
            text-decoration: none;
        }
        .reference-card a:hover {
            text-decoration: underline;
        }
        .stats-img {
            width: 100%;
            border-radius: 10px;
            margin-top: 10px;
        }
        @media (min-width: 576px) { /* Small screens */
    #reference-list .reference-card {
        width: 20%;
        height: 250px;
        font-size: small;
        }
}
@media (min-width: 768px) { /* Medium screens */
    #reference-list .reference-card {
        width: 20%;
        height: 250px;
        font-size: small;
     }
}
@media (min-width: 992px) { /* Large screens */
    #reference-list .reference-card {   width: 20%;
        height: 250px;
        font-size: small; }
}
@media (min-width: 1200px) { /* Extra large screens */
    #reference-list .reference-card {   width: 20%;
        height: 250px;
        font-size:small; }
}
#selected-year{
    color: #de803c;
    font-weight: bold;
}

p{
    font-size: xx-small; 
}
    </style>
</head>
<body>
    <div class="desc">
        <h1 class="text-center">Reinforcement Learning Algorithms in Robotics</h1>
        <strong>
            Reinforcement Learning (RL) has emerged as a transformative approach for training autonomous agents to perform complex tasks through trial-and-error interactions.
            This page provides an overview of reinforcement learning (RL) algorithms applied in robotics.
            Filters allow you to explore algorithms based on specific dates, types, policy updates, and contributions.
        </strong>
    </div>

    <div class="container py-4">
        <div class="row">
            <!-- Left: Filters -->
            <div class="col-lg-3 col-md-4">
                <div class="filterC">
                    <h4>Filters</h4>

                    <!-- Filter by Year (2020-2024) -->
                    <div class="mb-4">
                        <label for="year-range" class="form-label">Filter by Year:</label>
                        <input type="range" class="form-range" id="year-range" min="2020" max="2024" step="1" value="2020">
                        <div class="d-flex justify-content-between">
                            <span>2020</span>
                            <span>2021</span>
                            <span>2022</span>
                            <span>2023</span>
                            <span>2024</span>
                        </div>
                        <strong>Year From: <span id="selected-year">2020</span> To 2024</strong>
                    </div>

                    <!-- Filter by Algorithm -->
                    <div class="mb-4">
                        <label for="algorithm-select" class="form-label">Filter by Algorithm:</label>
                        <select id="algorithm-select" class="form-select">
                            <option value="">All Algorithms</option>
                            <option value="DDPG">Deep Deterministic Policy Gradient (DDPG)</option>
                            <option value="PPO">Proximal Policy Optimization (PPO)</option>
                            <option value="A3C">Asynchronous Advantage Actor-Critic (A3C)</option>
                            <option value="TD3">Twin Delayed Deep Deterministic Policy Gradient (TD3)</option>
                            <option value="SAC">Soft Actor-Critic (SAC)</option>
                        </select>
                    </div>

                    <!-- Filter by Type
                    <div class="mb-4">
                        <label class="form-label">Type:</label><br>
                        <div class="form-check">
                            <input class="form-check-input" type="checkbox" name="Model" value="ModelBased"> <!--name="critere1" value="Critere1-1"
                            <label class="form-check-label">Model-based</label>
                        </div>
                        <div class="form-check">
                            <input class="form-check-input" type="checkbox" name="Model" value="ModelFree"> <!--name="critere1" value="Critere1-2"
                            <label class="form-check-label">Model-free</label>
                        </div>
                    </div>-->

                      <!-- Filter by Robot Type -->
                      <div class="mb-4">
                        <label class="form-label">Robot:</label><br>
                        <div class="form-check">
                            <input class="form-check-input" type="checkbox" name="Robot" value="Aerial">
                            <label class="form-check-label">Aerial</label>
                        </div>
                        <div class="form-check">
                            <input class="form-check-input" type="checkbox" name="Robot" value="Marine">
                            <label class="form-check-label">Marine</label>
                        </div>
                        <div class="form-check">
                            <input class="form-check-input" type="checkbox" name="Robot" value="Mobile">
                            <label class="form-check-label">Mobile</label>
                        </div>
                        <div class="form-check">
                            <input class="form-check-input" type="checkbox" name="Robot" value="Manipulator">
                            <label class="form-check-label">Manipulator</label>
                        </div>
                        <div class="form-check">
                            <input class="form-check-input" type="checkbox" name="Robot" value="Legged">
                            <label class="form-check-label">Legged</label>
                        </div>
                    </div>
                    <!-- Filter by Policy Update
                    <div class="mb-4">
                        <label class="form-label">Policy Update:</label><br>
                        <div class="form-check">
                            <input class="form-check-input" type="checkbox" name="Policy" value="OnPolicy"> name="critere2" value="Critere2-1"
                            <label class="form-check-label">On-Policy</label>
                        </div>
                        <div class="form-check">
                            <input class="form-check-input" type="checkbox" name="Policy" value="OffPolicy"> name="critere2" value="Critere2-2"
                            <label class="form-check-label">Off-Policy</label>
                        </div>
                    </div>  -->

                    <!-- Statistics Section -->
                    <h5>Statistics</h5>
                        <a href="https://observablehq.com/d/ab2dc00ea8984e34" target="_blank">
                            <img src="marine.png" class="stats-icon">
                        </a>
                        <a href="barchart.html" target="_blank">
                            <img src="total.png" class="stats-icon">
                        </a>
                </div>
            </div>

            <!-- Right: Reference Matrix -->
            <div class="col-lg-9 col-md-8">
                <div class="row row-cols-1 row-cols-sm-2 row-cols-md-3 row-cols-lg-4 g-3" id="reference-list">

                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>Deep reinforcement learning based moving object grasping</strong>
                        <p>P. Chen, W. Lu, Information Sciences.</p>
                        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0020025521001158" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>Robot grasping method optimization using improved deep deterministic policy gradient algorithm of deep reinforcement learning</strong>
                        <p>H. Zhang, F. Wang, J. Wang, B. Cui, Review of Scientific Instruments.</p>
                        <a href="https://pubs.aip.org/aip/rsi/article-abstract/92/2/025114/369268/Robot-grasping-method-optimization-using-improved" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>Decentralized multi-agent control of a manipulator in continuous task learning</strong>
                        <p>A. A. Shahid, J. S. V. Sesin, D. Pecioski, F. Braghin, D. Piga, L. Roveda, Applied Sciences.</p>
                        <a href="https://www.mdpi.com/2076-3417/11/21/10227" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>Ensemble bootstrapped deep deterministic policy gradient for vision-based robotic grasping</strong>
                        <p>W. Liu, L. Peng, J. Cao, X. Fu, Y. Liu, Z. Pan, J. Yang, IEEE Access.</p>
                        <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9316755" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2022">
                        <strong>Continuous control actions learning and adaptation for robotic manipulation through reinforcement learning</strong>
                        <p>A. A. Shahid, D. Piga, F. Braghin, L. Roveda, Autonomous Robots.</p>
                        <a href="https://link.springer.com/article/10.1007/s10514-022-10034-z" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>Towards safe control of continuum manipulator using shielded multiagent reinforcement learning</strong>
                        <p>G. Ji, J. Yan, J. Du, W. Yan, J. Chen, Y. Lu, J. Rojas, S. S. Cheng, IEEE Robotics and Automation Letters.</p>
                        <a href="https://ieeexplore.ieee.org/abstract/document/9488207" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>Learn to grasp unknown objects in robotic manipulation</strong>
                        <p>A. Al-Shanoon, H. Lang, Y. Wang, Y. Zhang, W. Hong, Intelligent Service Robotics.</p>
                        <a href="https://dl.acm.org/doi/abs/10.1007/s11370-021-00380-9" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>Applying deep reinforcement learning to cable driven parallel robots for balancing unstable loads: a ball case study</strong>
                        <p>A. Grimshaw, J. Oyekan, Frontiers in Robotics and AI.</p>
                        <a href="https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2020.611203/full" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>Learning deep energy shaping policies for stability-guaranteed manipulation</strong>
                        <p>S. A. Khader, H. Yin, P. Falco, D. Kragic, IEEE Robotics and Automation Letters.</p>
                        <a href="https://ieeexplore.ieee.org/document/9536404" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2022">
                        <strong>Learning to cooperate: A hierarchical cooperative dual robot arm approach for underactuated pick-and-placing</strong>
                        <p>S. De Witte, T. Van Hauwermeiren, T. Lefebvre, G. Crevecoeur, IEEE/ASME Transactions on Mechatronics.</p>
                        <a href="https://ieeexplore.ieee.org/abstract/document/9788476" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2023">
                        <strong>Grasping living objects with adversarial behaviors using inverse reinforcement learning</strong>
                        <p>Z. Hu, Y. Zheng, J. Pan, IEEE Transactions on Robotics.</p>
                        <a href="https://ieeexplore.ieee.org/document/10024050" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2023">
                        <strong>Dexterous robotic manipulation using deep reinforcement learning and knowledge transfer for complex sparse reward-based tasks</strong>
                        <p>Q. Wang, F. R. Sanchez, R. McCarthy, D. C. Bulens, K. McGuinness, N. O’Connor, M. Wüthrich, F. Widmaier, S. Bauer, S. J. Redmond, Expert Systems.</p>
                        <a href="https://chatgpt.com/c/674725b5-a0dc-800e-9c28-7c1e677f3832" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2024">
                        <strong>Synergistic pushing and grasping for enhanced robotic manipulation using deep reinforcement learning</strong>
                        <p>B. A. Shiferaw, T. F. Agidew, A. S. Alzahrani, R. Srinivasagan, Actuators.</p>
                        <a href="https://www.mdpi.com/2076-0825/13/8/316" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2024">
                        <strong>A novel robotic grasping method for moving objects based on multi-agent deep reinforcement learning</strong>
                        <p>Y. Huang, D. Liu, Z. Liu, K. Wang, Q. Wang, J. Tan, Robotics and Computer-Integrated Manufacturing.</p>
                        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0736584523001199" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>Constrained motion planning of free-float dual-arm space manipulator via deep reinforcement learning</strong>
                        <p>Y. Li, X. Hao, Y. She, S. Li, M. Yu, Aerospace Science and Technology.</p>
                        <a href="https://www.mdpi.com/2226-4310/9/3/163" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2020">
                        <strong>Self-configuring robot path planning with obstacle avoidance via deep reinforcement learning</strong>
                        <p>B. Sangiovanni, G. P. Incremona, M. Piastra, A. Ferrara, IEEE Control Systems Letters.</p>
                        <a href="https://www.semanticscholar.org/paper/7a82b421e3fbf3c1d3e9511c65a56653cf0d09fc" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>Reinforcement learning-based collision-free path planner for redundant robot in narrow duct</strong>
                        <p>X. Hua, G. Wang, J. Xu, K. Chen, Journal of Intelligent Manufacturing.</p>
                        <a href="https://www.springerprofessional.de/en/reinforcement-learning-based-collision-free-path-planner-for-red/18016934" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2022">
                        <strong>Collision-free path planning for welding manipulator via hybrid algorithm of deep reinforcement learning and inverse kinematics</strong>
                        <p>J. Zhong, T. Wang, L. Cheng, Complex & Intelligent Systems.</p>
                        <a href="https://www.semanticscholar.org/paper/Collision-free-path-planning-for-welding-via-hybrid-Zhong-Wang/ac1b49652a33a6d46d220aa8b8b6ade01c68c855" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2022">
                        <strong>A deep reinforcement learning based method for real-time path planning and dynamic obstacle avoidance</strong>
                        <p>P. Chen, J. Pei, W. Lu, M. Li, Neurocomputing.</p>
                        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231222005367" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2022">
                        <strong>Constrained motion planning of 7-dof space manipulator via deep reinforcement learning combined with artificial potential field</strong>
                        <p>Y. Li, D. Li, W. Zhu, J. Sun, X. Zhang, S. Li, Aerospace.</p>
                        <a href="https://www.mdpi.com/2226-4310/9/3/163" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>Deep reinforcement learning-based path planning for multi-arm manipulators with periodically moving obstacles</strong>
                        <p>E. Prianto, J.-H. Park, J.-H. Bae, J.-S. Kim, Applied Sciences.</p>
                        <a href="https://www.mdpi.com/2076-3417/11/6/2587" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>An obstacles avoidance method for serial manipulator based on reinforcement learning and artificial potential field</strong>
                        <p>H. Li, D. Gong, J. Yu, International Journal of Intelligent Robotics and Applications.</p>
                        <a href="https://link.springer.com/article/10.1007/s41315-021-00172-5" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>Sim2real learning of obstacle avoidance for robotic manipulators in uncertain environments</strong>
                        <p>T. Zhang, K. Zhang, J. Lin, W.-Y. G. Louie, H. Huang, IEEE Robotics and Automation Letters.</p>
                        <a href="https://ieeexplore.ieee.org/document/9555228/" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2022">
                        <strong>A motion planning algorithm for live working manipulator integrating pso and reinforcement learning driven by model and data</strong>
                        <p>T. Ku, J. Lee, J. Liu, Y. Lin, X. Liu, Frontiers in Energy Research.</p>
                        <a href="https://www.frontiersin.org/journals/energy-research/articles/10.3389/fenrg.2022.957869/full" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2017">
                        <strong>Reinforcement learning of manipulation and grasping using dynamical movement primitives for a humanoidlike mobile manipulator</strong>
                        <p>Z. Li, T. Zhao, F. Chen, Y. Hu, C.-Y. Su, T. Fukuda, IEEE/ASME Transactions on Mechatronics.</p>
                        <a href="https://www.semanticscholar.org/paper/Reinforcement-Learning-of-Manipulation-and-Grasping-Li-Zhao/634896dbae6587330812ff65885602647ee0f371" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2020">
                        <strong>Reinforcement learning in dual-arm trajectory planning for a free-floating space robot</strong>
                        <p>Y.-H. Wu, Z.-C. Yu, C.-Y. Li, M.-J. He, B. Hua, Z.-M. Chen, Aerospace Science and Technology.</p>
                        <a href="https://www.sciencedirect.com/science/article/abs/pii/S1270963819325660" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2020">
                        <strong>Motion planning of robot manipulators for a smoother path using a twin delayed deep deterministic policy gradient with hindsight experience replay</strong>
                        <p>M. Kim, D.-K. Han, J.-H. Park, J.-S. Kim, Applied Sciences.</p>
                        <a href="https://www.mdpi.com/2076-3417/10/2/575" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2024">
                        <strong>Path planning of 6-dof free-floating space robotic manipulators using reinforcement learning</strong>
                        <p>A. Al Ali, J.-F. Shi, Z. H. Zhu, Acta Astronautica.</p>
                        <a href="https://www.sciencedirect.com/science/article/pii/S009457652400451X" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2023">
                        <strong>Reinforcement learning in robotic motion planning by combined experience-based planning and self-imitation learning</strong>
                        <p>S. Luo, L. Schomaker, Robotics and Autonomous Systems.</p>
                        <a href="https://www.sciencedirect.com/science/article/pii/S0921889023001847" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2023">
                        <strong>Reinforcement learning with prior policy guidance for motion planning of dual-arm free-floating space robot</strong>
                        <p>Y. Cao, S. Wang, X. Zheng, W. Ma, X. Xie, L. Liu, Aerospace Science and Technology.</p>
                        <a href="https://www.sciencedirect.com/science/article/abs/pii/S1270963822007726" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2024">
                        <strong>Reinforcement learning for path planning of free-floating space robotic manipulator with collision avoidance and observation noise</strong>
                        <p>A. Al Ali, Z. H. Zhu, Frontiers in Control Engineering.</p>
                        <a href="https://www.frontiersin.org/journals/control-engineering/articles/10.3389/fcteg.2024.1394668/full" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2020">
                        <strong>Reinforcement learning control of a flexible two-link manipulator: an experimental investigation</strong>
                        <p>W. He, H. Gao, C. Zhou, C. Yang, Z. Li, IEEE Transactions on Systems, Man, and Cybernetics: Systems.</p>
                        <a href="https://uwe-repository.worktribe.com/output/5827665/reinforcement-learning-control-of-a-flexible-two-link-manipulator-an-experimental-investigation" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2020">
                        <strong>Decentralized tracking optimization control for partially unknown fuzzy interconnected systems via reinforcement learning method</strong>
                        <p>K. Zhang, H. Zhang, Y. Mu, C. Liu, IEEE Transactions on Fuzzy Systems.</p>
                        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231223011360" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2020">
                        <strong>A vibration control method for hybrid-structured flexible manipulator based on sliding mode control and reinforcement learning</strong>
                        <p>T. Long, E. Li, Y. Hu, L. Yang, J. Fan, Z. Liang, R. Guo, IEEE transactions on neural networks and learning systems.</p>
                        <a href="https://ieeexplore.ieee.org/document/9062328/" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>Reinforcement learning-based fixed time trajectory tracking control for uncertain robotic manipulators with input saturation</strong>
                        <p>S. Cao, L. Sun, J. Jiang, Z. Zuo, IEEE Transactions on Neural Networks and Learning Systems.</p>
                        <a href="https://pubmed.ncbi.nlm.nih.gov/34653006/" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>Ddpg-based adaptive robust tracking control for aerial manipulators with decoupling approach</strong>
                        <p>Y.-C. Liu, C.-Y. Huang, IEEE Transactions on Cybernetics.</p>
                        <a href="https://ieeexplore.ieee.org/document/9345436" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>Stochastic genetic algorithm-assisted fuzzy q-learning for robotic manipulators</strong>
                        <p>A. Kukker, R. Sharma, Arabian Journal for Science and Engineering.</p>
                        <a href="https://link.springer.com/article/10.1007/s13369-021-05379-z" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>Adaptive reinforcement learning enhanced motion/force control strategy for multirobot systems</strong>
                        <p>P. N. Dao, D. K. Do, D. K. Nguyen, Mathematical Problems in Engineering.</p>
                        <a href="https://onlinelibrary.wiley.com/doi/10.1155/2021/5560277" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2022">
                        <strong>A fuzzy logic reinforcement learning control with spring-damper device for space robot capturing satellite</strong>
                        <p>A. Zhu, H. Ai, L. Chen, Applied Sciences.</p>
                        <a href="https://www.mdpi.com/2076-3417/12/5/2662" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>Observer-based adaptive control of robot manipulators using reinforcement learning and the fourier series expansion</strong>
                        <p>G. Khodamipour, S. Khorashadizadeh, M. Farshad, Transactions of the Institute of Measurement and Control.</p>
                        <a href="https://www.sciencedirect.com/science/article/abs/pii/S1568494607000622" target="_blank">[Read more]</a>
                    </div>
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2022">
                        <strong>A real-world application of markov chain monte carlo method for bayesian trajectory control of a robotic manipulator</strong>
                        <p>V. T. Aghaei, A. Ağababaoğlu, S. Yıldırım, A. Onat, ISA Transactions.</p>
                        <a href="https://pubmed.ncbi.nlm.nih.gov/34148651/" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2020">
                        <strong>Optimized interaction control for robot manipulator interacting with flexible environment</strong>
                        <p>X. Liu, S. S. Ge, F. Zhao, X. Mei, IEEE/ASME Transactions on Mechatronics.</p>
                        <a href="https://ieeexplore.ieee.org/document/9310291/" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2022">
                        <strong>Performance-based data-driven optimal tracking control of shape memory alloy actuated manipulator through reinforcement learning</strong>
                        <p>H. Liu, Q. Cheng, J. Xiao, L. Hao, Engineering Applications of Artificial Intelligence.</p>
                        <a href="https://www.sciencedirect.com/science/article/pii/S0952197622002238" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2022">
                        <strong>Model-free dynamic control of robotic joints with integrated elastic ligaments</strong>
                        <p>A. Robbins, M. Ho, M. Teodorescu, Robotics and Autonomous Systems.</p>
                        <a href="https://www.sciencedirect.com/science/article/pii/S0921889022000860" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2023">
                        <strong>Reinforcement learning-based control for an upper limb rehabilitation robot</strong>
                        <p>Z. Al-Jumaili, T. Siddique, R. Fareh, M. A. Y. Abdallah, M. R. Khan, M. H. Rahman, M. Bettayeb, 2023 Advances in Science and Engineering Technology International Conferences (ASET).</p>
                        <a href="https://doi.org/10.1109/ASET56582.2023.10180597" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2023">
                        <strong>Reinforcement learning fractional order pid controller for upper limb rehabilitation robot</strong>
                        <p>K. Choutri, R. Fareh, M. H. Rahman, M. Bettayeb, S. Fadloun, M. Lagha, 2023 International Conference on Fractional Differentiation and Its Applications (ICFDA).</p>
                        <a href="https://doi.org/10.1109/ICFDA58234.2023.10153385" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2024">
                        <strong>Deep reinforcement learning with reward shaping for tracking control and vibration suppression of flexible link manipulator</strong>
                        <p>J. K. Viswanadhapalli, V. K. Elumalai, S. Shivram, S. Shah, D. Mahajan, Applied Soft Computing.</p>
                        <a href="https://www.semanticscholar.org/paper/Deep-reinforcement-learning-with-reward-shaping-for-J.-V./7b499db177abc20692beb41dbb7bda283fb37ac2" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2023">
                        <strong>Optimal tracking control for robot manipulators with input constraint based reinforcement learning</strong>
                        <p>N. D. Dien, N. T. Luy, L. K. Lai, T. T. Hai, Journal of Computer Science and Cybernetics.</p>
                        <a href="https://link.springer.com/content/pdf/10.1007/978-3-031-22200-9_61" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2023">
                        <strong>A new reinforcement learning fault-tolerant tracking control method with application to baxter robot</strong>
                        <p>J.-W. Zhu, Z.-Y. Dong, Z.-J. Yang, X. Wang, IEEE/ASME Transactions on Mechatronics.</p>
                        <a href="https://ieeexplore.ieee.org/document/10251067/" target="_blank">[Read more]</a>
                    </div>

                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2023">
                        <strong>Optimal tracking control for robot manipulators with asymmetric saturation torques based on reinforcement learning</strong>
                        <p>N. D. Dien, N. T. Luy, L. K. Lai, Journal of Computer Science and Cybernetics.</p>
                        <a href="https://vjs.ac.vn/index.php/jcc/article/view/17641" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2024">
                        <strong>A deep reinforcement learning framework for control of robotic manipulators in simulated environments</strong>
                        <p>C. Calderon-Cordova, R. Sarango, D. Castillo, V. Lakshminarayanan, IEEE Access.</p>
                        <a href="http://ieeexplore.ieee.org/document/10606462/" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2024">
                        <strong>RL-based adaptive controller for high precision reaching in a soft robot arm</strong>
                        <p>M. S. Nazeer, C. Laschi, E. Falotico, IEEE Transactions on Robotics.</p>
                        <a href="https://ieeexplore.ieee.org/document/10478622" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>Multi-agent reinforcement learning for redundant robot control in task-space</strong>
                        <p>A. Perrusquía, W. Yu, X. Li, International Journal of Machine Learning and Cybernetics.</p>
                        <a href="https://www.mdpi.com/2075-1702/12/12/902" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>Coordinated control based on reinforcement learning for dual-arm continuum manipulators in space capture missions</strong>
                        <p>D. Jiang, Z. Cai, H. Peng, Z. Wu, Journal of Aerospace Engineering.</p>
                        <a href="https://www.semanticscholar.org/paper/caa372351a633a7bc81bd0445ff0e85b0b007c8f" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>The control method of twin delayed deep deterministic policy gradient with rebirth mechanism to multi-dof manipulator</strong>
                        <p>Y. Hou, H. Hong, Z. Sun, D. Xu, Z. Zeng, Electronics.</p>
                        <a href="https://www.mdpi.com/2079-9292/10/7/870" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2021">
                        <strong>Customizing skills for assistive robotic manipulators, an inverse reinforcement learning approach with error-related potentials</strong>
                        <p>I. Batzianoulis, F. Iwane, S. Wei, C. G. P. R. Correia, R. Chavarriaga, J. d. R. Millán, A. Billard, Communications Biology.</p>
                        <a href="https://www.nature.com/articles/s42003-021-02891-8" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2022">
                        <strong>Extensively explored and evaluated actor-critic with expert-guided policy learning and fuzzy feedback reward for robotic trajectory generation</strong>
                        <p>F. Ying, H. Liu, R. Jiang, M. Dong, IEEE Transactions on Industrial Informatics.</p>
                        <a href="https://ieeexplore.ieee.org/document/9684700/" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2019">
                        <strong>Double deep q-network for trajectory generation of a commercial 7dof redundant manipulator</strong>
                        <p>E. Marchesini, D. Corsi, A. Benfatti, A. Farinelli, P. Fiorini, 2019 Third IEEE International Conference on Robotic Computing (IRC).</p>
                        <a href="https://www.computer.org/csdl/proceedings-article/irc/2019/924500a421/18M7huvTF8Q" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2023">
                        <strong>An efficiently convergent deep reinforcement learning-based trajectory planning method for manipulators in dynamic environments</strong>
                        <p>L. Zheng, Y. Wang, R. Yang, S. Wu, R. Guo, E. Dong, Journal of Intelligent & Robotic Systems.</p>
                        <a href="https://link.springer.com/content/pdf/10.1007/s10846-023-01822-5.pdf" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2024">
                        <strong>Trajectory planning of robotic manipulator in dynamic environment exploiting drl</strong>
                        <p>O. Ahmad, Z. Hussain, H. Naeem, arXiv preprint arXiv:2403.16652.</p>
                        <a href="https://arxiv.org/abs/2403.16652" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2023">
                        <strong>Shared control of robot manipulators with obstacle avoidance: A deep reinforcement learning approach</strong>
                        <p>M. Rubagotti, B. Sangiovanni, A. Nurbayeva, G. P. Incremona, A. Ferrara, A. Shintemirov, IEEE Control Systems Magazine.</p>
                        <a href="https://ieeexplore.ieee.org/document/10015627/" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Manipulator" data-year="2023">
                        <strong>Robotic table wiping via reinforcement learning and whole-body trajectory optimization</strong>
                        <p>T. Lew, S. Singh, M. Prats, J. Bingham, J. Weisz, B. Holson, X. Zhang, V. Sindhwani, Y. Lu, F. Xia, et al., 2023 IEEE International Conference on Robotics and Automation (ICRA).</p>
                        <a href="https://ieeexplore.ieee.org/iel7/10160211/10160212/10161283.pdf" target="_blank">[Read more]</a>
                    </div>
                    <!---------  manipulator 168---------------------------------------------------------------->
                     <!--Mobile-- from 169---- 173------------------------------------------------------------------>
                     <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2023">
                        <strong>Adaptive formation control of leader–follower mobile robots using reinforcement learning and the fourier series expansion</strong>
                        <p>G. Khodamipour, S. Khorashadizadeh, M. Farshad, ISA Transactions.</p>
                        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0019057823001179" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2017">
                        <strong>Incremental q-learning strategy for adaptive pid control of mobile robots</strong>
                        <p>I. Carlucho, M. De Paula, S. A. Villar, G. G. Acosta, Expert Systems with Applications.</p>
                        <a href="https://ri.conicet.gov.ar/bitstream/handle/11336/58321/CONICET_Digital_Nro.841f128e-6c12-4513-b30f-278980f87d18_A.pdf;jsessionid=5DE977325EB05998DD04E2DE2FFCC035?sequence=2" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2018">
                        <strong>Adaptive neural network tracking control-based reinforcement learning for wheeled mobile robots with skidding and slipping</strong>
                        <p>S. Li, L. Ding, H. Gao, C. Chen, Z. Liu, Z. Deng, Neurocomputing.</p>
                        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231217319136" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2020">
                        <strong>An adaptive deep reinforcement learning approach for mimo pid control of mobile robots</strong>
                        <p>I. Carlucho, M. De Paula, G. G. Acosta, ISA Transactions.</p>
                        <a href="ttps://www.sciencedirect.com/science/article/abs/pii/S0019057820300781" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2018">
                        <strong>Adaptive image-based visual servoing with temporary loss of the visual signal</strong>
                        <p>H. Shi, G. Sun, Y. Wang, K.-S. Hwang, IEEE Transactions on Industrial Informatics.</p>
                        <a href="https://ieeexplore.ieee.org/document/8434098/" target="_blank">[Read more]</a>
                    </div>
                          
                 
                    
                  
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2020">
                        <strong>An intelligent non-integer pid controller-based deep reinforcement learning: Implementation and experimental results</strong>
                        <p>M. Gheisarnejad, M. H. Khooban, IEEE Transactions on Industrial Electronics.</p>
                        <a href="https://pure.au.dk/portal/en/publications/an-intelligent-non-integer-pid-controller-based-deep-reinforcemen" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2021">
                        <strong>A hybrid tracking control strategy for nonholonomic wheeled mobile robot incorporating deep reinforcement learning approach</strong>
                        <p>X. Gao, R. Gao, P. Liang, Q. Zhang, R. Deng, W. Zhu, IEEE Access.</p>
                        <a href="https://ieeexplore.ieee.org/iel7/6287639/9312710/09330502.pdf" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2021">
                        <strong>Policy-based deep reinforcement learning for visual servoing control of mobile robots with visibility constraints</strong>
                        <p>Z. Jin, J. Wu, A. Liu, W.-A. Zhang, L. Yu, IEEE Transactions on Industrial Electronics.</p>
                        <a href="https://ieeexplore.ieee.org/document/9351748/" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="SAC-PID" data-id="Robot-Mobile" data-year="2022">
                        <strong>A self-adaptive sac-pid control approach based on reinforcement learning for mobile robots</strong>
                        <p>X. Yu, Y. Fan, S. Xu, L. Ou, International Journal of Robust and Nonlinear Control.</p>
                        <a href="https://onlinelibrary.wiley.com/doi/full/10.1002/rnc.5662" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2022">
                        <strong>Reinforcement learning-based tracking control for a three mecanum wheeled mobile robot</strong>
                        <p>D. Zhang, G. Wang, Z. Wu, IEEE Transactions on Neural Networks and Learning Systems.</p>
                        <a href="https://doi.org/10.1109/tnnls.2022.3185055" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2022">
                        <strong>Position control of a mobile robot through deep reinforcement learning</strong>
                        <p>F. Quiroga, G. Hermosilla, G. Farias, E. Fabregas, G. Montenegro, Applied Sciences.</p>
                        <a href="https://www.mdpi.com/2076-3417/12/14/7194" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2022">
                        <strong>Barrier function-based safe reinforcement learning for formation control of mobile robots</strong>
                        <p>X. Zhang, Y. Peng, W. Pan, X. Xu, H. Xie, 2022 International Conference on Robotics and Automation (ICRA).</p>
                        <a href="https://ieeexplore.ieee.org/document/9811604" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2021">
                        <strong>Distributed reinforcement learning containment control for multiple nonholonomic mobile robots</strong>
                        <p>W. Xiao, Q. Zhou, Y. Liu, H. Li, R. Lu, IEEE Transactions on Circuits and Systems I: Regular Papers.</p>
                        <a href="https://ieeexplore.ieee.org/document/9594719" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2019">
                        <strong>Mobile robot navigation based on deep reinforcement learning</strong>
                        <p>X. Ruan, D. Ren, X. Zhu, J. Huang, 2019 Chinese Control and Decision Conference (CCDC).</p>
                        <a href="https://ieeexplore.ieee.org/document/8832393/" target="_blank">[Read more]</a>
                    </div>
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2021">
                        <strong>Badgr: An autonomous self-supervised learning-based navigation system</strong>
                        <p>G. Kahn, P. Abbeel, S. Levine, IEEE Robotics and Automation Letters.</p>
                        <a href="https://ieeexplore.ieee.org/ielaam/7083369/9285111/9345970-aam.pdf" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2021">
                        <strong>Incremental learning for autonomous navigation of mobile robots based on deep reinforcement learning</strong>
                        <p>M. Luong, C. Pham, Journal of Intelligent & Robotic Systems.</p>
                        <a href="https://link.springer.com/article/10.1007/s10846-020-01262-5" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2020">
                        <strong>Olfactory-based navigation via model-based reinforcement learning and fuzzy inference methods</strong>
                        <p>L. Wang, S. Pang, J. Li, IEEE Transactions on Fuzzy Systems.</p>
                        <a href="https://ieeexplore.ieee.org/document/9147023/" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2021">
                        <strong>Learning data-driven decision-making policies in multi-agent environments for autonomous systems</strong>
                        <p>J. Hook, S. El-Sedky, V. De Silva, A. Kondoz, Cognitive Systems Research.</p>
                        <a href="https://www.sciencedirect.com/science/article/pii/S1389041720300693" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2021">
                        <strong>Danger-aware adaptive composition of drl agents for self-navigation</strong>
                        <p>W. Zhang, Y. Zhang, N. Liu, Unmanned Systems.</p>
                        <a href="https://www.worldscientific.com/doi/abs/10.1142/S2301385021500011?srsltid=AfmBOooxykexKj88OcoLPanFUMyKRTrvFT18uoE64l0fJg5o2NU7kScG" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2022">
                        <strong>Target-driven visual navigation in indoor scenes using reinforcement learning and imitation learning</strong>
                        <p>Q. Fang, X. Xu, X. Wang, Y. Zeng, CAAI Transactions on Intelligence Technology.</p>
                        <a href="https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/cit2.12043" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2021">
                        <strong>Land: Learning to navigate from disengagements</strong>
                        <p>G. Kahn, P. Abbeel, S. Levine, IEEE Robotics and Automation Letters.</p>
                        <a href="https://ieeexplore.ieee.org/iel7/7083369/9285111/09357900.pdf" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2019">
                        <strong>Solving the optimal path planning of a mobile robot using improved q-learning</strong>
                        <p>E. S. Low, P. Ong, K. C. Cheah, Robotics and Autonomous Systems.</p>
                        <a href="https://www.sciencedirect.com/science/article/pii/S0921889018308285" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2022">
                        <strong>Path planning method of mobile robot using improved deep reinforcement learning</strong>
                        <p>W. Wang, Z. Wu, H. Luo, B. Zhang, Journal of Electrical and Computer Engineering.</p>
                        <a href="https://onlinelibrary.wiley.com/doi/10.1155/2022/5433988" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2019">
                        <strong>Primal: Pathfinding via reinforcement and imitation multi-agent learning</strong>
                        <p>G. Sartoretti, J. Kerr, Y. Shi, G. Wagner, T. S. Kumar, S. Koenig, H. Choset, IEEE Robotics and Automation Letters.</p>
                        <a href="https://ieeexplore.ieee.org/document/9366340/" target="_blank">[Read more]</a>
                    </div>
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2021">
                        <strong>An improved dyna-q algorithm for mobile robot path planning in unknown dynamic environment</strong>
                        <p>M. Pei, H. An, B. Liu, C. Wang, IEEE Transactions on Systems, Man, and Cybernetics: Systems.</p>
                        <a href="https://ieeexplore.ieee.org/document/9495840/" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2017">
                        <strong>Application of deep reinforcement learning in mobile robot path planning</strong>
                        <p>J. Xin, H. Zhao, D. Liu, M. Li, 2017 Chinese Automation Congress (CAC).</p>
                        <a href="https://ieeexplore.ieee.org/document/8244061/" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2020">
                        <strong>Deep reinforcement learning for indoor mobile robot path planning</strong>
                        <p>J. Gao, W. Ye, J. Guo, Z. Li, Sensors.</p>
                        <a href="https://www.mdpi.com/1424-8220/20/19/5493" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2021">
                        <strong>Reinforcement based mobile robot path planning with improved dynamic window approach in unknown environment</strong>
                        <p>L. Chang, L. Shan, C. Jiang, Y. Dai, Autonomous Robots.</p>
                        <a href="https://www.mdpi.com/2076-0825/13/1/24" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2020">
                        <strong>Mobile robot path planning in dynamic environments through globally guided reinforcement learning</strong>
                        <p>B. Wang, Z. Liu, Q. Li, A. Prorok, IEEE Robotics and Automation Letters.</p>
                        <a href="https://www.scribd.com/document/639916930/Untitled" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2021">
                        <strong>Mobile robot path optimization technique based on reinforcement learning algorithm in warehouse environment</strong>
                        <p>H. Lee, J. Jeong, Applied Sciences.</p>
                        <a href="https://www.mdpi.com/2076-3417/11/3/1209" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2021">
                        <strong>A fusion method of local path planning for mobile robots based on lstm neural network and reinforcement learning</strong>
                        <p>N. Guo, C. Li, T. Gao, G. Liu, Y. Li, D. Wang, Mathematical Problems in Engineering.</p>
                        <a href="https://onlinelibrary.wiley.com/doi/10.1155/2021/5524232" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2021">
                        <strong>Deep reinforcement learning for mapless goal-driven robot navigation</strong>
                        <p>M. Dobrevski, D. Skočaj, International Journal of Advanced Robotic Systems.</p>
                        <a href="https://journals.sagepub.com/doi/full/10.1177/1729881421992621" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2022">
                        <strong>Highly optimized q-learning-based bees approach for mobile robot path planning in static and dynamic environments</strong>
                        <p>T. Bonny, M. Kashkash, Journal of Field Robotics.</p>
                        <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.22052" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2022">
                        <strong>A hierarchical path planning approach with multi-sarsa based on topological map</strong>
                        <p>S. Wen, Y. Jiang, B. Cui, K. Gao, F. Wang, Sensors.</p>
                        <a href="https://www.mdpi.com/1424-8220/22/6/2367" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2022">
                        <strong>Path-following and obstacle avoidance control of nonholonomic wheeled mobile robot based on deep reinforcement learning</strong>
                        <p>X. Cheng, S. Zhang, S. Cheng, Q. Xia, J. Zhang, Applied Sciences.</p>
                        <a href="https://www.mdpi.com/2076-3417/12/14/6874" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2023">
                        <strong>Mobile service robot path planning using deep reinforcement learning</strong>
                        <p>A. N. Kumaar, S. Kochuvila, IEEE Access.</p>
                        <a href="https://ieeexplore.ieee.org/document/10238717/" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2020">
                        <strong>Voronoi-based multi-robot autonomous exploration in unknown environments via deep reinforcement learning</strong>
                        <p>J. Hu, H. Niu, J. Carrasco, B. Lennox, F. Arvin, IEEE Transactions on Vehicular Technology.</p>
                        <a href="https://ieeexplore.ieee.org/document/9244647" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2021">
                        <strong>A behavior-based mobile robot navigation method with deep reinforcement learning</strong>
                        <p>J. Li, M. Ran, H. Wang, L. Xie, Unmanned Systems.</p>
                        <a href="https://www.worldscientific.com/doi/10.1142/S2301385021410041?srsltid=AfmBOooMlQzPxuWtA4wa3iCbFKLbjy8xxnP-r0Lb5LXLvTvXP9JA_JH6" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2019">
                        <strong>Bnd*-ddqn: Learn to steer autonomously through deep reinforcement learning</strong>
                        <p>K. Wu, H. Wang, M. A. Esfahani, S. Yuan, IEEE Transactions on Cognitive and Developmental Systems.</p>
                        <a href="https://ieeexplore.ieee.org/document/8764461/" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2021">
                        <strong>Multimodal deep reinforcement learning with auxiliary task for obstacle avoidance of indoor mobile robot</strong>
                        <p>H. Song, A. Li, T. Wang, M. Wang, Sensors.</p>
                        <a href="https://www.mdpi.com/1424-8220/21/4/1363" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2021">
                        <strong>Reinforcement learning-based dynamic obstacle avoidance and integration of path planning</strong>
                        <p>J. Choi, G. Lee, C. Lee, Intelligent Service Robotics.</p>
                        <a href="https://doi.org/10.1007/s11370-021-00387-2" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2023">
                        <strong>Adaptive image-based moving-target tracking control of wheeled mobile robots with visibility maintenance and obstacle avoidance</strong>
                        <p>S.-L. Dai, J. Liang, K. Lu, X. Jin, IEEE Transactions on Control Systems Technology.</p>
                        <a href="https://ieeexplore.ieee.org/document/10324407/" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2023">
                        <strong>Dynamic obstacle avoidance and path planning through reinforcement learning</strong>
                        <p>K. Almazrouei, I. Kamel, T. Rabie, Applied Sciences.</p>
                        <a href="https://www.mdpi.com/2076-3417/13/14/8174" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2024">
                        <strong>Reinforcement learning driven dynamic obstacle avoidance for mobile robot trajectory tracking</strong>
                        <p>H. Xiao, C. Chen, G. Zhang, C. P. Chen, Knowledge-Based Systems.</p>
                        <a href="https://www.sciencedirect.com/science/article/pii/S0950705124006087" target="_blank">[Read more]</a>
                    </div>
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2024">
                        <strong>A dynamic reward-enhanced q-learning approach for efficient path planning and obstacle avoidance in mobile robotics</strong>
                        <p>A. Gharbi, Applied Computing and Informatics.</p>
                        <a href="https://www.emerald.com/insight/content/doi/10.1108/aci-10-2023-0089/full/html" target="_blank">[Read more]</a>
                    </div>
                    
                    <div class="col reference-card" data-algorithm="" data-id="Robot-Mobile" data-year="2024">
                        <strong>Enhanced method for reinforcement learning based dynamic obstacle avoidance by assessment of collision risk</strong>
                        <p>F. Hart, O. Okhrin, Neurocomputing.</p>
                        <a href="https://www.sciencedirect.com/science/article/pii/S0925231223012201" target="_blank">[Read more]</a>
                    </div>
                    <!------------------------------------------------------------------------->
                     <!---- mobile -214 ---------------------------------------------->
                    
<!--------------------------Aerial--------------------------------------------------->
                    
                   
<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2018">
    <strong>Prm-rl: Long-range robotic navigation tasks by combining reinforcement learning and sampling-based planning</strong>
    <p>A. Faust, K. Oslund, O. Ramirez, A. Francis, L. Tapia, M. Fiser, J. Davidson, 2018 IEEE International Conference on Robotics and Automation (ICRA).</p>
    <a href="https://ieeexplore.ieee.org/iel7/8449910/8460178/08461096.pdf" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2017">
    <strong>Automated aerial suspended cargo delivery through reinforcement learning</strong>
    <p>A. Faust, I. Palunko, P. Cruz, R. Fierro, L. Tapia, Artificial Intelligence.</p>
    <a href="https://www.sciencedirect.com/science/article/pii/S0004370214001416" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2024">
    <strong>UAV air combat autonomous trajectory planning method based on robust adversarial reinforcement learning</strong>
    <p>L. Wang, S. Zheng, S. Tai, H. Liu, T. Yue, Aerospace Science and Technology.</p>
    <a href="https://www.sciencedirect.com/science/article/pii/S1270963824005339" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2016">
    <strong>Autonomous navigation of UAV by using real-time model-based reinforcement learning</strong>
    <p>N. Imanberdiyev, C. Fu, E. Kayacan, I.-M. Chen, 2016 14th International Conference on Control, Automation, Robotics and Vision (ICARCV).</p>
    <a href="https://ieeexplore.ieee.org/document/7838739/" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2020">
    <strong>Multi-agent deep reinforcement learning-based trajectory planning for multi-UAV assisted mobile edge computing</strong>
    <p>L. Wang, K. Wang, C. Pan, W. Xu, N. Aslam, L. Hanzo, IEEE Transactions on Cognitive Communications and Networking.</p>
    <a href="https://ieeexplore.ieee.org/document/9209079/" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2020">
    <strong>A two-stage reinforcement learning approach for multi-UAV collision avoidance under imperfect sensing</strong>
    <p>D. Wang, T. Fan, T. Han, J. Pan, IEEE Robotics and Automation Letters.</p>
    <a href="https://ieeexplore.ieee.org/document/9001167/" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2019">
    <strong>Deep reinforcement learning for drone delivery</strong>
    <p>G. Muñoz, C. Barrado, E. Çetin, E. Salami, Drones.</p>
    <a href="https://www.mdpi.com/2504-446X/3/3/72" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2020">
    <strong>Leveraging UAVs for coverage in cell-free vehicular networks: A deep reinforcement learning approach</strong>
    <p>M. Samir, D. Ebrahimi, C. Assi, S. Sharafeddine, A. Ghrayeb, IEEE Transactions on Mobile Computing.</p>
    <a href="https://ieeexplore.ieee.org/document/9082162/" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2021">
    <strong>Distributed multi-agent meta learning for trajectory design in wireless drone networks</strong>
    <p>Y. Hu, M. Chen, W. Saad, H. V. Poor, S. Cui, IEEE Journal on Selected Areas in Communications.</p>
    <a href="https://ieeexplore.ieee.org/iel7/49/5594698/09457160.pdf" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="TD3" data-id="Robot-Aerial" data-year="2024">
    <strong>Autonomous localized path planning algorithm for UAVs based on TD3 strategy</strong>
    <p>Z. Feiyu, L. Dayan, W. Zhengxu, M. Jianlin, W. Niya, Scientific Reports.</p>
    <a href="https://www.nature.com/articles/s41598-024-51349-4" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2020">
    <strong>Drone-cell trajectory planning and resource allocation for highly mobile networks: A hierarchical DRL approach</strong>
    <p>W. Shi, J. Li, H. Wu, C. Zhou, N. Cheng, X. Shen, IEEE Internet of Things Journal.</p>
    <a href="https://ieeexplore.ieee.org/document/9179787" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2021">
    <strong>Task offloading and trajectory control for UAV-assisted mobile edge computing using deep reinforcement learning</strong>
    <p>L. Zhang, Z.-Y. Zhang, L. Min, C. Tang, H.-Y. Zhang, Y.-H. Wang, P. Cai, IEEE Access.</p>
    <a href="https://ieeexplore.ieee.org/document/9395130/" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2021">
    <strong>An innovative bio-inspired flight controller for quad-rotor drones: Quad-rotor drone learning to fly using reinforcement learning</strong>
    <p>A. R. Dooraki, D.-J. Lee, Robotics and Autonomous Systems.</p>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S092188902030511X" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2021">
    <strong>Trajectory design and access control for air–ground coordinated communications system with multiagent deep reinforcement learning</strong>
    <p>R. Ding, Y. Xu, F. Gao, X. Shen, IEEE Internet of Things Journal.</p>
    <a href="https://ieeexplore.ieee.org/abstract/document/9363308/" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2024">
    <strong>Path planning for unmanned aerial vehicle via off-policy reinforcement learning with enhanced exploration</strong>
    <p>Z. Wang, W. Gao, G. Li, Z. Wang, M. Gong, IEEE Transactions on Emerging Topics in Computational Intelligence.</p>
    <a href="https://ieeexplore.ieee.org/document/10478216/" target="_blank">[Read more]</a>
</div>
<div class="col reference-card" data-algorithm="SAC" data-id="Robot-Aerial" data-year="2024">
    <strong>A soft actor-critic based reinforcement learning approach for motion planning of UAVs using depth images</strong>
    <p>A. N. Mishra, S. Papakonstantinou, V. Gollnick, 2024 AIAA DATC/IEEE 43rd Digital Avionics Systems Conference (DASC).</p>
    <a href="https://ieeexplore.ieee.org/document/10748743/" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2023">
    <strong>A hybrid human-in-the-loop deep reinforcement learning method for UAV motion planning for long trajectories with unpredictable obstacles</strong>
    <p>S. Zhang, Y. Li, F. Ye, X. Geng, Z. Zhou, T. Shi, Drones.</p>
    <a href="https://www.mdpi.com/2504-446X/7/5/311" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2023">
    <strong>Path planning of unmanned aerial vehicle in complex environments based on state detection twin delayed deep deterministic policy gradient</strong>
    <p>D. Zhang, Z. Xuan, Y. Zhang, J. Yao, X. Li, X. Li, Machines.</p>
    <a href="https://www.mdpi.com/2075-1702/11/1/108" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2023">
    <strong>UAV path planning with terrain constraints for aerial scanning</strong>
    <p>J. Yuan, Z. Liu, X. Xiong, Y. Ai, L. Chen, B. Tian, IEEE Transactions on Intelligent Vehicles.</p>
    <a href="https://ieeexplore.ieee.org/document/10225682" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2019">
    <strong>Reinforcement learning for UAV attitude control</strong>
    <p>W. Koch, R. Mancuso, R. West, A. Bestavros, ACM Transactions on Cyber-Physical Systems.</p>
    <a href="https://dl.acm.org/doi/10.1145/3301273" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2013">
    <strong>A reinforcement learning approach towards autonomous suspended load manipulation using aerial robots</strong>
    <p>I. Palunko, A. Faust, P. Cruz, L. Tapia, R. Fierro, 2013 IEEE International Conference on Robotics and Automation.</p>
    <a href="https://ieeexplore.ieee.org/document/6631276" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2019">
    <strong>Low-level control of a quadrotor with deep model-based reinforcement learning</strong>
    <p>N. O. Lambert, D. S. Drew, J. Yaconelli, S. Levine, R. Calandra, K. S. Pister, IEEE Robotics and Automation Letters.</p>
    <a href="https://drl.ece.utah.edu/wp-content/uploads/sites/155/2021/07/lambert-ral2019.pdf" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2015">
    <strong>Autonomous construction of multiple structures using learning automata: Description and experimental validation</strong>
    <p>S. R. B. dos Santos, S. N. Givigi, C. L. Nascimento, IEEE Systems Journal.</p>
    <a href="https://ieeexplore.ieee.org/document/7018006" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2021">
    <strong>Maneuvering target tracking of UAV based on MN-DDPG and transfer learning</strong>
    <p>B. Li, Z.-p. Yang, D.-q. Chen, S.-y. Liang, H. Ma, Defence Technology.</p>
    <a href="https://www.sciencedirect.com/science/article/pii/S2214914720304815" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2016">
    <strong>Game of drones: UAV pursuit-evasion game with type-2 fuzzy logic controllers tuned by reinforcement learning</strong>
    <p>E. Camci, E. Kayacan, 2016 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE).</p>
    <a href="https://ieeexplore.ieee.org/document/7737744" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2021">
    <strong>Data-driven fault-tolerant control for attitude synchronization of nonlinear quadrotors</strong>
    <p>W. Zhao, H. Liu, F. L. Lewis, IEEE Transactions on Automatic Control.</p>
    <a href="https://ieeexplore.ieee.org/document/9329117" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2021">
    <strong>Deep reinforcement learning multi-UAV trajectory control for target tracking</strong>
    <p>J. Moon, S. Papaioannou, C. Laoudias, P. Kolios, S. Kim, IEEE Internet of Things Journal.</p>
    <a href="https://ieeexplore.ieee.org/document/9406813" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2021">
    <strong>Deep reinforcement learning for quadrotor path following with adaptive velocity</strong>
    <p>B. Rubí, B. Morcego, R. Pérez, Autonomous Robots.</p>
    <a href="https://link.springer.com/article/10.1007/s10514-020-09951-8" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2022">
    <strong>Reinforcement learning-based tracking control for a quadrotor unmanned aerial vehicle under external disturbances</strong>
    <p>H. Liu, B. Li, B. Xiao, D. Ran, C. Zhang, International Journal of Robust and Nonlinear Control.</p>
    <a href="https://doi.org/10.1002/rnc.6334" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2022">
    <strong>Reinforcement learning control for a 2-DOF helicopter with state constraints: Theory and experiments</strong>
    <p>Z. Zhao, W. He, C. Mu, T. Zou, K.-S. Hong, H.-X. Li, IEEE Transactions on Automation Science and Engineering.</p>
    <a href="https://doi.org/10.1109/tase.2022.3215738" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2023">
    <strong>Target tracking control of UAV through deep reinforcement learning</strong>
    <p>B. Ma, Z. Liu, W. Zhao, J. Yuan, H. Long, X. Wang, Z. Yuan, IEEE Transactions on Intelligent Transportation Systems.</p>
    <a href="https://ieeexplore.ieee.org/document/10061339" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2024">
    <strong>A novel guided deep reinforcement learning tracking control strategy for multirotors</strong>
    <p>H. Hua, Y. Wang, H. Zhong, H. Zhang, Y. Fang, IEEE Transactions on Automation Science and Engineering.</p>
    <a href="https://ieeexplore.ieee.org/document/10468052" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2024">
    <strong>Constrained reinforcement learning using distributional representation for trustworthy quadrotor UAV tracking control</strong>
    <p>Y. Wang, D. Boyle, IEEE Transactions on Automation Science and Engineering.</p>
    <a href="https://ieeexplore.ieee.org/document/10614102" target="_blank">[Read more]</a>
</div>
<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2024">
    <strong>Optimized fuzzy attitude control of quadrotor unmanned aerial vehicle using adaptive reinforcement learning strategy</strong>
    <p>G. Wen, D. Yu, Y. Zhao, IEEE Transactions on Aerospace and Electronic Systems.</p>
    <a href="https://ieeexplore.ieee.org/document/10531634" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2024">
    <strong>Adaptive state-constrained/model-free iterative sliding mode control for aerial robot trajectory tracking</strong>
    <p>C. An, J. Zhou, K. Wang, Applied Mathematics and Mechanics.</p>
    <a href="https://link.springer.com/article/10.1007/s10483-024-3103-8" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2016">
    <strong>Learning deep control policies for autonomous aerial vehicles with MPC-guided policy search</strong>
    <p>T. Zhang, G. Kahn, S. Levine, P. Abbeel, 2016 IEEE International Conference on Robotics and Automation (ICRA).</p>
    <a href="https://ieeexplore.ieee.org/document/7487175" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2019">
    <strong>Generalization through simulation: Integrating simulated and real data into deep reinforcement learning for vision-based autonomous flight</strong>
    <p>K. Kang, S. Belkhale, G. Kahn, P. Abbeel, S. Levine, 2019 International Conference on Robotics and Automation (ICRA).</p>
    <a href="https://www.semanticscholar.org/paper/Generalization-through-Simulation%3A-Integrating-and-Kang-Belkhale/75fca92da207b950a83061536b8d8cb7ad1a2d33" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2019">
    <strong>Memory-based deep reinforcement learning for obstacle avoidance in UAV with limited environment knowledge</strong>
    <p>A. Singla, S. Padakandla, S. Bhatnagar, IEEE Transactions on Intelligent Transportation Systems.</p>
    <a href="https://ieeexplore.ieee.org/document/8917687" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2021">
    <strong>UAV navigation in high dynamic environments: A deep reinforcement learning approach</strong>
    <p>G. Tong, N. Jiang, L. Biyue, Z. Xi, W. Ya, D. Wenbo, Chinese Journal of Aeronautics.</p>
    <a href="https://www.sciencedirect.com/science/article/pii/S1000936120302247" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2020">
    <strong>A two-stage reinforcement learning approach for multi-UAV collision avoidance under imperfect sensing</strong>
    <p>D. Wang, T. Fan, T. Han, J. Pan, IEEE Robotics and Automation Letters.</p>
    <a href="https://ieeexplore.ieee.org/document/9001167" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2020">
    <strong>Deep reinforcement learning based local planner for UAV obstacle avoidance using demonstration data</strong>
    <p>L. He, N. Aouf, J. F. Whidborne, B. Song, arXiv preprint arXiv:2008.02521.</p>
    <a href="https://www.academia.edu/91364965/Deep_Reinforcement_Learning_based_Local_Planner_for_UAV_Obstacle_Avoidance_using_Demonstration_Data" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2022">
    <strong>Obstacle avoidance for UAS in continuous action space using deep reinforcement learning</strong>
    <p>J. Hu, X. Yang, W. Wang, P. Wei, L. Ying, Y. Liu, IEEE Access.</p>
    <a href="https://bpb-us-w2.wpmucdn.com/web.seas.gwu.edu/dist/9/15/files/2022/09/IEEE-2022_Jueming.pdf" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2022">
    <strong>A vision based deep reinforcement learning algorithm for UAV obstacle avoidance</strong>
    <p>J. Roghair, A. Niaraki, K. Ko, A. Jannesari, Intelligent Systems and Applications: Proceedings of the 2021 Intelligent Systems Conference (IntelliSys).</p>
    <a href="https://www.mdpi.com/2673-2688/2/3/23" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2022">
    <strong>Autonomous obstacle avoidance of UAV based on deep reinforcement learning</strong>
    <p>S. Yang, G. Yu, Z. Meng, Z. Wang, H. Li, Journal of Intelligent & Fuzzy Systems.</p>
    <a href="https://dl.acm.org/doi/10.3233/JIFS-211192" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2023">
    <strong>UAV path planning and obstacle avoidance based on reinforcement learning in 3D environments</strong>
    <p>G.-T. Tu, J.-G. Juang, Actuators.</p>
    <a href="https://www.mdpi.com/2076-0825/12/2/57" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2023">
    <strong>Q-learning-based unmanned aerial vehicle path planning with dynamic obstacle avoidance</strong>
    <p>A. Sonny, S. R. Yeduri, L. R. Cenkeramaddi, Applied Soft Computing.</p>
    <a href="https://www.sciencedirect.com/science/article/pii/S1568494623007913" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2023">
    <strong>Learning-based navigation and collision avoidance through reinforcement for UAVs</strong>
    <p>R. Azzam, M. Chehadeh, O. A. Hay, M. A. Humais, I. Boiko, Y. Zweiri, IEEE Transactions on Aerospace and Electronic Systems.</p>
    <a href="https://ieeexplore.ieee.org/document/10182280" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2024">
    <strong>Hybrid machine learning and reinforcement learning framework for adaptive UAV obstacle avoidance</strong>
    <p>W. Skarka, R. Ashfaq, Aerospace.</p>
    <a href="https://www.mdpi.com/2226-4310/11/11/870" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2024">
    <strong>Autonomous obstacle avoidance and target tracking of UAV: Transformer for observation sequence in reinforcement learning</strong>
    <p>W. Jiang, T. Cai, G. Xu, Y. Wang, Knowledge-Based Systems.</p>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0950705124002399" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2024">
    <strong>Autonomous obstacle avoidance algorithm for unmanned aerial vehicles based on deep reinforcement learning</strong>
    <p>Y. Gao, L. Ren, T. Shi, T. Xu, J. Ding, Engineering Letters.</p>
    <a href="https://www.engineeringletters.com/issues_v32/issue_3/EL_32_3_20.pdf" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2019">
    <strong>A deep reinforcement learning strategy for UAV autonomous landing on a moving platform</strong>
    <p>A. Rodriguez-Ramos, C. Sampedro, H. Bavle, P. De La Puente, P. Campoy, Journal of Intelligent & Robotic Systems.</p>
    <a href="https://link.springer.com/article/10.1007/s10846-018-0891-8" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2018">
    <strong>Distributed deep reinforcement learning for fighting forest fires with a network of aerial robots</strong>
    <p>R. N. Haksar, M. Schwager, 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS).</p>
    <a href="https://ieeexplore.ieee.org/document/8593539" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2018">
    <strong>Reinforcement learning for autonomous UAV navigation using function approximation</strong>
    <p>H. X. Pham, H. M. La, D. Feil-Seifer, L. Van Nguyen, 2018 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR).</p>
    <a href="https://ieeexplore.ieee.org/document/8468611/" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2018">
    <strong>Laser-based reactive navigation for multirotor aerial robots using deep reinforcement learning</strong>
    <p>C. Sampedro, H. Bavle, A. Rodriguez-Ramos, P. de La Puente, P. Campoy, 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS).</p>
    <a href="https://ieeexplore.ieee.org/document/8593706" target="_blank">[Read more]</a>
</div>
<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2021">
    <strong>Deep reinforcement learning for drone navigation using sensor data</strong>
    <p>V. J. Hodge, R. Hawkins, R. Alexander, Neural Computing and Applications.</p>
    <a href="https://link.springer.com/article/10.1007/s00521-020-05097-x" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2020">
    <strong>Deep reinforcement learning for mapless navigation of unmanned aerial vehicles</strong>
    <p>R. B. Grando, J. C. de Jesus, P. L. Drews-Jr, 2020 Latin American Robotics Symposium (LARS), 2020 Brazilian Symposium on Robotics (SBR), and 2020 Workshop on Robotics in Education (WRE).</p>
    <a href="https://ieeexplore.ieee.org/document/9307015" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2022">
    <strong>Double critic deep reinforcement learning for mapless 3D navigation of unmanned aerial vehicles</strong>
    <p>R. B. Grando, J. C. de Jesus, V. A. Kich, A. H. Kolling, P. L. J. Drews-Jr, Journal of Intelligent & Robotic Systems.</p>
    <a href="https://link.springer.com/article/10.1007/s10846-021-01568-y" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2022">
    <strong>Depth-CUPRL: Depth-imaged contrastive unsupervised prioritized representations in reinforcement learning for mapless navigation of unmanned aerial vehicles</strong>
    <p>J. C. de Jesus, V. A. Kich, A. H. Kolling, R. B. Grando, R. S. Guerra, P. L. Drews, 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS).</p>
    <a href="https://ieeexplore.ieee.org/document/9982161" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2023">
    <strong>DOCRL: Double critic deep reinforcement learning for mapless navigation of a hybrid aerial underwater vehicle with medium transition</strong>
    <p>R. B. Grando, J. C. De Jesus, V. A. Kich, A. H. Kolling, M. G. Mateus, R. S. Guerra, P. L. Drews, 2023 Latin American Robotics Symposium (LARS), 2023 Brazilian Symposium on Robotics (SBR), and 2023 Workshop on Robotics in Education (WRE).</p>
    <a href="https://ieeexplore.ieee.org/document/10333008" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2024">
    <strong>Energy-aware hierarchical reinforcement learning based on the predictive energy consumption algorithm for search and rescue aerial robots in unknown environments</strong>
    <p>M. Ramezani, M. Amiri Atashgah, Drones.</p>
    <a href="https://www.mdpi.com/2504-446X/8/7/283" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Aerial" data-year="2024">
    <strong>Exploring the effectiveness of deep reinforcement learning for autonomous robot navigation</strong>
    <p>M. A. Rasol, A. F. Abdulqader, A. Hussain, Z. M. Imneef, B. Goyal, A. Dogra, M. Mittal, 2024 11th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions)(ICRITO).</p>
    <a href="https://ieeexplore.ieee.org/document/10522404" target="_blank">[Read more]</a>
</div>

<!----------------------------------- 276-->
<!-------------------Marine 277-332-------------------------------------->
<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2020">
    <strong>Trajectory planning for navigation aiding of autonomous underwater vehicles</strong>
    <p>Ø. Sture, P. Norgren, M. Ludvigsen, IEEE Access.</p>
    <a href="https://ieeexplore.ieee.org/document/9123363" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2021">
    <strong>End-to-end AUV motion planning method based on soft actor-critic</strong>
    <p>X. Yu, Y. Sun, X. Wang, G. Zhang, Sensors.</p>
    <a href="https://www.mdpi.com/1424-8220/21/17/5893" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2022">
    <strong>Comprehensive ocean information-enabled AUV path planning via reinforcement learning</strong>
    <p>M. Xi, J. Yang, J. Wen, H. Liu, Y. Li, H. H. Song, IEEE Internet of Things Journal.</p>
    <a href="https://ieeexplore.ieee.org/document/9723442/" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2022">
    <strong>Path planning based on deep reinforcement learning for autonomous underwater vehicles under ocean current disturbance</strong>
    <p>Z. Chu, F. Wang, T. Lei, C. Luo, IEEE Transactions on Intelligent Vehicles.</p>
    <a href="https://ieeexplore.ieee.org/document/9722969" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2023">
    <strong>Comprehensive ocean information-enabled AUV motion planning based on reinforcement learning</strong>
    <p>Y. Li, X. He, Z. Lu, P. Jing, Y. Su, Remote Sensing.</p>
    <a href="https://www.mdpi.com/2072-4292/15/12/3077" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2023">
    <strong>Adaptive formation motion planning and control of autonomous underwater vehicles using deep reinforcement learning</strong>
    <p>B. Hadi, A. Khosravi, P. Sarhadi, IEEE Journal of Oceanic Engineering.</p>
    <a href="https://ieeexplore.ieee.org/document/10214138" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2023">
    <strong>End-to-end AUV local motion planning method based on deep reinforcement learning</strong>
    <p>X. Lyu, Y. Sun, L. Wang, J. Tan, L. Zhang, Journal of Marine Science and Engineering.</p>
    <a href="https://www.mdpi.com/2077-1312/11/9/1796" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2023">
    <strong>Binocular vision-based motion planning of an AUV: A deep reinforcement learning approach</strong>
    <p>J. Yan, K. You, W. Cao, X. Yang, X. Guan, IEEE Transactions on Intelligent Vehicles.</p>
    <a href="https://ieeexplore.ieee.org/document/10271703/" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2024">
    <strong>Trajectory planning aided unmanned surface vehicle optimization communication method with hierarchical reinforcement learning</strong>
    <p>C. Tang, H. Shi, L. Zhang, Ocean Engineering.</p>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0029801824015634" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2024">
    <strong>Adaptive energy-efficient reinforcement learning for AUV 3D motion planning in complex underwater environments</strong>
    <p>J. Wen, A. Wang, J. Zhu, F. Xia, Z. Peng, W. Zhang, Ocean Engineering.</p>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0029801824024491" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2024">
    <strong>Hybrid motion planning and formation control of multi-AUV systems based on DRL</strong>
    <p>B. Hadi, A. Khosravi, P. Sarhadi, 2024 American Control Conference (ACC).</p>
    <a href="https://ieeexplore.ieee.org/document/10644333" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2023">
    <strong>Multi-USV system antidisturbance cooperative searching based on the reinforcement learning method</strong>
    <p>Y. Liu, C. Chen, D. Qu, Y. Zhong, H. Pu, J. Luo, Y. Peng, J. Xie, R. Zhou, IEEE Journal of Oceanic Engineering.</p>
    <a href="https://ieeexplore.ieee.org/document/10261771" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2024">
    <strong>A novel approach to multi-USV cooperative search in unknown dynamic marine environment using reinforcement learning</strong>
    <p>R. Song, S. Gao, Y. Li, Neural Computing and Applications.</p>
    <a href="https://link.springer.com/article/10.1007/s00521-024-10524-4" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2024">
    <strong>USV formation navigation decision-making through hybrid deep reinforcement learning using self-attention mechanism</strong>
    <p>Z. Cui, W. Guan, X. Zhang, Expert Systems with Applications.</p>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417424017731" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2023">
    <strong>USV path planning under marine environment simulation using DWA and safe reinforcement learning</strong>
    <p>T. Qu, G. Xiong, H. Ali, X. Dong, Y. Han, Z. Shen, 2023 IEEE 19th International Conference on Automation Science and Engineering (CASE).</p>
    <a href="https://ieeexplore.ieee.org/document/10260584" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2023">
    <strong>Autonomous berthing motion planning for under-actuated ASV based on imagined sub-goals and soft actor-critic</strong>
    <p>Z. Li, Y. Wang, L. Wang, International Conference on Offshore Mechanics and Arctic Engineering.</p>
    <a href="https://asmedigitalcollection.asme.org/OMAE/proceedings-abstract/OMAE2024/87837/V05BT06A076/1202498" target="_blank">[Read more]</a>
</div>
<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2024">
    <strong>Intelligent decision-making method for AUV path planning against ocean current disturbance via reinforcement learning</strong>
    <p>J. Wen, H. Dai, J. He, L. Sun, L. Gao, IEEE Internet of Things Journal.</p>
    <a href="https://ieeexplore.ieee.org/document/10490109" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2020">
    <strong>Deep interactive reinforcement learning for path following of autonomous underwater vehicle</strong>
    <p>Q. Zhang, J. Lin, Q. Sha, B. He, G. Li, IEEE Access.</p>
    <a href="https://ieeexplore.ieee.org/document/8976170" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2021">
    <strong>Attention-based meta-reinforcement learning for tracking control of AUV with time-varying dynamics</strong>
    <p>P. Jiang, S. Song, G. Huang, IEEE Transactions on Neural Networks and Learning Systems.</p>
    <a href="https://ieeexplore.ieee.org/document/9439903/" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2021">
    <strong>Deep reinforcement learning for vectored thruster autonomous underwater vehicle control</strong>
    <p>T. Liu, Y. Hu, H. Xu, Complexity.</p>
    <a href="https://onlinelibrary.wiley.com/doi/10.1155/2021/6649625" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2021">
    <strong>Integrated localization and tracking for AUV with model uncertainties via scalable sampling-based reinforcement learning approach</strong>
    <p>J. Yan, X. Li, X. Yang, X. Luo, C. Hua, X. Guan, IEEE Transactions on Systems, Man, and Cybernetics: Systems.</p>
    <a href="https://ieeexplore.ieee.org/document/9633120" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2021">
    <strong>Novel TD3 based AUV path tracking control</strong>
    <p>Y. Zhang, R. Li, Y. Li, T. Zhang, Y. Zhuang, Y. Song, 2021 China Automation Congress (CAC).</p>
    <a href="https://ieeexplore.ieee.org/document/9727467" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2022">
    <strong>Control of an AUV with completely unknown dynamics and multi-asymmetric input constraints via off-policy reinforcement learning</strong>
    <p>M. Mohammadi, M. M. Arefi, N. Vafamand, O. Kaynak, Neural Computing and Applications.</p>
    <a href="https://link.springer.com/article/10.1007/s00521-021-06476-8" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2022">
    <strong>Reinforcement learning based model-free optimized trajectory tracking strategy design for an AUV</strong>
    <p>K. Duan, S. Fong, C. P. Chen, Neurocomputing.</p>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231221015423" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2022">
    <strong>Sliding mode heading control for AUV based on continuous hybrid model-free and model-based reinforcement learning</strong>
    <p>D. Wang, Y. Shen, J. Wan, Q. Sha, G. Li, G. Chen, B. He, Applied Ocean Research.</p>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0141118721004247" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2022">
    <strong>AUV position tracking and trajectory control based on fast-deployed deep reinforcement learning method</strong>
    <p>Y. Fang, Z. Huang, J. Pu, J. Zhang, Ocean Engineering.</p>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0029801821017340" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2024">
    <strong>General reinforcement learning control for AUV manoeuvring in turbulent flows</strong>
    <p>A. K. Lidtke, D. Rijpkema, B. Düz, Ocean Engineering.</p>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0029801824018766" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2024">
    <strong>Tracking control of AUV via novel soft actor-critic and suboptimal demonstrations</strong>
    <p>Y. Zhang, T. Zhang, Y. Li, Y. Zhuang, Ocean Engineering.</p>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0029801823029244" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2024">
    <strong>Learning-based tracking control of AUV: Mixed policy improvement and game-based disturbance rejection</strong>
    <p>J. Ye, H. Gao, M. Hu, Y. Bian, Q. Cui, X. Qin, R. Ding, CAAI Transactions on Intelligence Technology.</p>
    <a href="https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/cit2.12372" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2023">
    <strong>Scalable-MADDPG-based cooperative target invasion for a multi-USV system</strong>
    <p>C.-C. Wang, Y.-L. Wang, P. Shi, F. Wang, IEEE Transactions on Neural Networks and Learning Systems.</p>
    <a href="https://ieeexplore.ieee.org/document/10243453" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2022">
    <strong>USV path following controller based on DDPG with composite state-space and dynamic reward function</strong>
    <p>W. Zhong, H. Li, Y. Meng, X. Yang, Y. Feng, H. Ye, W. Liu, Ocean Engineering.</p>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0029801822017322" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2020">
    <strong>Path following optimization for an underactuated USV using smoothly-convergent deep reinforcement learning</strong>
    <p>Y. Zhao, X. Qi, Y. Ma, Z. Li, R. Malekian, M. A. Sotelo, IEEE Transactions on Intelligent Transportation Systems.</p>
    <a href="https://ieeexplore.ieee.org/document/9086759" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2022">
    <strong>Safe deep reinforcement learning-based adaptive control for USV interception mission</strong>
    <p>B. Du, B. Lin, C. Zhang, B. Dong, W. Zhang, Ocean Engineering.</p>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S002980182101756X" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2024">
    <strong>Multi-USV cooperative formation control via deep reinforcement learning with deceleration</strong>
    <p>C.-C. Wang, Y.-L. Wang, Q.-L. Han, W.-B. Xie, IEEE Transactions on Intelligent Vehicles.</p>
    <a href="https://ieeexplore.ieee.org/document/10621696" target="_blank">[Read more]</a>
</div>
<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2024">
    <strong>Reducing controller effort in a deep reinforcement learning-based autopilot for an underactuated ASV</strong>
    <p>J. Jose, R. S. Kumar, E. M. Coates, IFAC-PapersOnLine.</p>
    <a href="https://www.sciencedirect.com/science/article/pii/S2405896324017804" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2023">
    <strong>Deep reinforcement learning based tracking control of an autonomous surface vessel in natural waters</strong>
    <p>W. Wang, X. Cao, A. Gonzalez-Garcia, L. Yin, N. Hagemann, Y. Qiao, C. Ratti, D. Rus, 2023 IEEE International Conference on Robotics and Automation (ICRA).</p>
    <a href="https://ieeexplore.ieee.org/document/10160858" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2020">
    <strong>Model-reference reinforcement learning control of autonomous surface vehicles</strong>
    <p>Q. Zhang, W. Pan, V. Reppa, 2020 59th IEEE Conference on Decision and Control (CDC).</p>
    <a href="https://ieeexplore.ieee.org/document/9304347" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2023">
    <strong>Neural network model-based reinforcement learning control for AUV 3-D path following</strong>
    <p>D. Ma, X. Chen, W. Ma, H. Zheng, F. Qu, IEEE Transactions on Intelligent Vehicles.</p>
    <a href="https://ieeexplore.ieee.org/document/10143677" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2023">
    <strong>Adaptive optimal trajectory tracking control of AUVs based on reinforcement learning</strong>
    <p>Z. Li, M. Wang, G. Ma, ISA Transactions.</p>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0019057822006334" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2023">
    <strong>Adaptive reinforcement learning fault-tolerant control for AUVs with thruster faults based on the integral extended state observer</strong>
    <p>Z. Li, M. Wang, G. Ma, T. Zou, Ocean Engineering.</p>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0029801823001063" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2020">
    <strong>An obstacle avoiding method of autonomous underwater vehicle based on the reinforcement learning</strong>
    <p>W. Li, X. Yang, J. Yan, X. Luo, 2020 39th Chinese Control Conference (CCC).</p>
    <a href="https://ieeexplore.ieee.org/document/9188579" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2021">
    <strong>AUV obstacle avoidance planning based on deep reinforcement learning</strong>
    <p>J. Yuan, H. Wang, H. Zhang, C. Lin, D. Yu, C. Li, Journal of Marine Science and Engineering.</p>
    <a href="https://www.mdpi.com/2077-1312/9/11/1166" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2021">
    <strong>Deep reinforcement learning controller for 3D path following and collision avoidance by autonomous underwater vehicles</strong>
    <p>S. T. Havenstrøm, A. Rasheed, O. San, Frontiers in Robotics and AI.</p>
    <a href="https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2020.566037/full" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2023">
    <strong>Research on 3D obstacle avoidance of autonomous underwater vehicle based on deep reinforcement learning</strong>
    <p>T. Liu, J. Zhao, International Conference on Autonomous Unmanned Systems.</p>
    <a href="https://link.springer.com/chapter/10.1007/978-981-97-1095-9_36" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2024">
    <strong>AUV obstacle avoidance framework based on event-triggered reinforcement learning</strong>
    <p>S. Liu, C. Ma, R. Juan, Electronics.</p>
    <a href="https://www.mdpi.com/2079-9292/13/11/2030" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2024">
    <strong>Research on obstacle avoidance of underactuated autonomous underwater vehicle based on offline reinforcement learning</strong>
    <p>T. Liu, J. Huang, J. Zhao, Robotica.</p>
    <a href="https://www.cambridge.org/core/journals/robotica/article/research-on-obstacle-avoidance-of-underactuated-autonomous-underwater-vehicle-based-on-offline-reinforcement-learning/E9D766B78DDE9616AE90811799035A2B" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2024">
    <strong>Imitation learning from imperfect demonstrations for AUV path tracking and obstacle avoidance</strong>
    <p>T. Chen, Z. Zhang, Z. Fang, D. Jiang, G. Li, Ocean Engineering.</p>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0029801824006243" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2024">
    <strong>AUV collision avoidance strategy based on fuzzy reinforcement learning</strong>
    <p>X. Cao, J. Peng, W. Liu, L. Ren, C. Sun, IEEE Transactions on Intelligent Vehicles.</p>
    <a href="https://ieeexplore.ieee.org/document/10601514" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2024">
    <strong>Learning obstacle avoidance and predation in complex reef environments with deep reinforcement learning</strong>
    <p>J. Hou, C. He, T. Li, C. Zhang, Q. Zhou, Bioinspiration & Biomimetics.</p>
    <a href="https://iopscience.iop.org/article/10.1088/1748-3190/ad6544" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2023">
    <strong>Multi-USV cooperative chasing strategy based on obstacles assistance and deep reinforcement learning</strong>
    <p>W. Gan, X. Qu, D. Song, P. Yao, IEEE Transactions on Automation Science and Engineering.</p>
    <a href="https://ieeexplore.ieee.org/document/10269079" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2022">
    <strong>AUV path tracking with real-time obstacle avoidance via reinforcement learning under adaptive constraints</strong>
    <p>C. Zhang, P. Cheng, B. Du, B. Dong, W. Zhang, Ocean Engineering.</p>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0029801822008320" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2022">
    <strong>A learning method for AUV collision avoidance through deep reinforcement learning</strong>
    <p>J. Xu, F. Huang, D. Wu, Y. Cui, Z. Yan, X. Du, Ocean Engineering.</p>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0029801822013683" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2021">
    <strong>Robust ASV navigation through ground to water cross-domain deep reinforcement learning</strong>
    <p>R. Lambert, J. Li, L.-F. Wu, N. Mahmoudian, Frontiers in Robotics and AI.</p>
    <a href="https://ieeexplore.ieee.org/document/10802067" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2024">
    <strong>A deep reinforcement learning framework and methodology for reducing the sim-to-real gap in ASV navigation</strong>
    <p>L. F. Batista, J. Ro, A. Richard, P. Schroepfer, S. Hutchinson, C. Pradalier, 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS).</p>
    <a href="https://ieeexplore.ieee.org/document/10802067/" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2024">
    <strong>Decentralized multi-robot navigation for autonomous surface vehicles with distributional reinforcement learning</strong>
    <p>X. Lin, Y. Huang, F. Chen, B. Englot, arXiv preprint arXiv:2402.11799.</p>
    <a href="https://ieeexplore.ieee.org/document/10611668" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Marine" data-year="2024">
    <strong>Reinforcement learning based robot navigation using illegal actions for autonomous docking of surface vehicles in unknown environments</strong>
    <p>M. I. Pereira, A. M. Pinto, Engineering Applications of Artificial Intelligence.</p>
    <a href="https://www.sciencedirect.com/science/article/pii/S095219762400664X?dgcid=rss_sd_all" target="_blank">[Read more]</a>
</div>
<!---------------------------------------------------------  332-->
<!---------------------------Legged Robot 333 377-->
<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2024">
    <strong>Vapor: Legged robot navigation in unstructured outdoor environments using offline reinforcement learning</strong>
    <p>K. Weerakoon, A. J. Sathyamoorthy, M. Elnoor, D. Manocha, 2024 IEEE International Conference on Robotics and Automation (ICRA).</p>
    <a href="https://ieeexplore.ieee.org/document/10610132" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2020">
    <strong>Slope handling for quadruped robots using deep reinforcement learning and toe trajectory planning</strong>
    <p>A. S. Mastrogeorgiou, Y. S. Elbahrawy, A. Kecskeméthy, E. G. Papadopoulos, 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS).</p>
    <a href="https://ieeexplore.ieee.org/document/9341645" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2020">
    <strong>Guided constrained policy optimization for dynamic quadrupedal robot locomotion</strong>
    <p>S. Gangapurwala, A. Mitchell, I. Havoutis, IEEE Robotics and Automation Letters.</p>
    <a href="https://www.robots.ox.ac.uk/~mobile/drs/Papers/2020RAL_gangapurwala.pdf" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2021">
    <strong>Robust feedback motion policy design using reinforcement learning on a 3D digit bipedal robot</strong>
    <p>G. A. Castillo, B. Weng, W. Zhang, A. Hereid, 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS).</p>
    <a href="https://ieeexplore.ieee.org/document/9636467" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2021">
    <strong>Real-time trajectory adaptation for quadrupedal locomotion using deep reinforcement learning</strong>
    <p>S. Gangapurwala, M. Geisert, R. Orsolino, M. Fallon, I. Havoutis, 2021 IEEE International Conference on Robotics and Automation (ICRA).</p>
    <a href="https://ieeexplore.ieee.org/document/9561639" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2022">
    <strong>Reinforcement learning-based cascade motion policy design for robust 3D bipedal locomotion</strong>
    <p>G. A. Castillo, B. Weng, W. Zhang, A. Hereid, IEEE Access.</p>
    <a href="https://ieeexplore.ieee.org/document/9714352" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2022">
    <strong>M-A3C: A mean asynchronous advantage actor-critic reinforcement learning method for real-time gait planning of biped robot</strong>
    <p>J. Leng, S. Fan, J. Tang, H. Mou, J. Xue, Q. Li, IEEE Access.</p>
    <a href="https://ieeexplore.ieee.org/document/9779214" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2022">
    <strong>A motion planning and control method of quadruped robot based on deep reinforcement learning</strong>
    <p>W. Liu, B. Li, L. Hou, S. Yang, Y. Xu, L. Liu, 2022 IEEE International Conference on Robotics and Biomimetics (ROBIO).</p>
    <a href="https://ieeexplore.ieee.org/document/10011798" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2022">
    <strong>RLOC: Terrain-aware legged locomotion using reinforcement learning and optimal control</strong>
    <p>S. Gangapurwala, M. Geisert, R. Orsolino, M. Fallon, I. Havoutis, IEEE Transactions on Robotics.</p>
    <a href="https://ieeexplore.ieee.org/document/9779429" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2023">
    <strong>Designing a biped robot’s gait using reinforcement learning’s actor-critic method</strong>
    <p>J. D. Rose, T. Mohanaprakash, M. KrishnaRaj, S. Diviyasri, et al., 2023 International Conference on Inventive Computation Technologies (ICICT).</p>
    <a href="https://ieeexplore.ieee.org/document/10134079" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2023">
    <strong>A hierarchical framework for quadruped robots gait planning based on DDPG</strong>
    <p>Y. Li, Z. Chen, C. Wu, H. Mao, P. Sun, Biomimetics.</p>
    <a href="https://www.mdpi.com/2313-7673/8/5/382" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2024">
    <strong>Learning advanced locomotion for quadrupedal robots: A distributed multi-agent reinforcement learning framework with Riemannian motion policies</strong>
    <p>Y. Wang, R. Sagawa, Y. Yoshiyasu, Robotics.</p>
    <a href="https://www.mdpi.com/2218-6581/13/6/86" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2024">
    <strong>A motion planner based on mask-D3QN of quadruped robot motion for steam generator</strong>
    <p>B. Xu, X. Zhang, X. Yu, Y. Ou, K. Zhang, H. Cai, J. Zhao, J. Fan, Biomimetics.</p>
    <a href="https://www.mdpi.com/2313-7673/9/10/592" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2024">
    <strong>RL2AC: Reinforcement learning-based rapid online adaptive control for legged robot robust locomotion</strong>
    <p>S. Lyu, X. Lang, H. Zhao, H. Zhang, P. Ding, D. Wang, Proceedings of the Robotics: Science and Systems.</p>
    <a href="https://www.roboticsproceedings.org/rss20/p060.pdf" target="_blank">[Read more]</a>
</div>
<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2018">
    <strong>Feedback control for Cassie with deep reinforcement learning</strong>
    <p>Z. Xie, G. Berseth, P. Clary, J. Hurst, M. van de Panne, 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS).</p>
    <a href="https://ieeexplore.ieee.org/document/8593722/" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2021">
    <strong>Learning task space actions for bipedal locomotion</strong>
    <p>H. Duan, J. Dao, K. Green, T. Apgar, A. Fern, J. Hurst, 2021 IEEE International Conference on Robotics and Automation (ICRA).</p>
    <a href="https://ieeexplore.ieee.org/document/9561705" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2018">
    <strong>Sim-to-real: Learning agile locomotion for quadruped robots</strong>
    <p>J. Tan, T. Zhang, E. Coumans, A. Iscen, Y. Bai, D. Hafner, S. Bohez, V. Vanhoucke, arXiv preprint arXiv:1804.10332.</p>
    <a href="https://arxiv.org/abs/1804.10332" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2019">
    <strong>Learning agile and dynamic motor skills for legged robots</strong>
    <p>J. Hwangbo, J. Lee, A. Dosovitskiy, D. Bellicoso, V. Tsounis, V. Koltun, M. Hutter, Science Robotics.</p>
    <a href="https://www.science.org/doi/10.1126/scirobotics.aau5872" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2020">
    <strong>Learning quadrupedal locomotion over challenging terrain</strong>
    <p>J. Lee, J. Hwangbo, L. Wellhausen, V. Koltun, M. Hutter, Science Robotics.</p>
    <a href="https://www.science.org/doi/10.1126/scirobotics.abc5986" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2022">
    <strong>Learning robust perceptive locomotion for quadrupedal robots in the wild</strong>
    <p>T. Miki, J. Lee, J. Hwangbo, L. Wellhausen, V. Koltun, M. Hutter, Science Robotics.</p>
    <a href="https://www.science.org/doi/10.1126/scirobotics.abk2822" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2024">
    <strong>Reinforcement learning for reduced-order models of legged robots</strong>
    <p>Y.-M. Chen, H. Bui, M. Posa, 2024 IEEE International Conference on Robotics and Automation (ICRA).</p>
    <a href="https://ieeexplore.ieee.org/document/10610747" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2022">
    <strong>RLOC: Terrain-aware legged locomotion using reinforcement learning and optimal control</strong>
    <p>S. Gangapurwala, M. Geisert, R. Orsolino, M. Fallon, I. Havoutis, IEEE Transactions on Robotics.</p>
    <a href="https://ieeexplore.ieee.org/document/9779429" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2020">
    <strong>Quadruped robot locomotion in unknown terrain using deep reinforcement learning</strong>
    <p>M. Pei, D. Wu, C. Wang, 2020 3rd International Conference on Unmanned Systems (ICUS).</p>
    <a href="https://ieeexplore.ieee.org/document/9274920" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2020">
    <strong>Reinforcement learning for quadrupedal locomotion with design of continual–hierarchical curriculum</strong>
    <p>T. Kobayashi, T. Sugino, Engineering Applications of Artificial Intelligence.</p>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0952197620302207" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2020">
    <strong>Walking control of a biped robot on static and rotating platforms based on hybrid reinforcement learning</strong>
    <p>A. Xi, C. Chen, IEEE Access.</p>
    <a href="https://ieeexplore.ieee.org/document/9163340" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2020">
    <strong>Stability control of a biped robot on a dynamic platform based on hybrid reinforcement learning</strong>
    <p>A. Xi, C. Chen, Sensors.</p>
    <a href="https://www.mdpi.com/1424-8220/20/16/4468" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2021">
    <strong>Reinforcement learning for robust parameterized locomotion control of bipedal robots</strong>
    <p>Z. Li, X. Cheng, X. B. Peng, P. Abbeel, S. Levine, G. Berseth, K. Sreenath, 2021 IEEE International Conference on Robotics and Automation (ICRA).</p>
    <a href="https://ieeexplore.ieee.org/document/9560769" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2021">
    <strong>Robust biped locomotion using deep reinforcement learning on top of an analytical control approach</strong>
    <p>M. Kasaei, M. Abreu, N. Lau, A. Pereira, L. P. Reis, Robotics and Autonomous Systems.</p>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0921889021001858" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2021">
    <strong>A behavior-based reinforcement learning approach to control walking bipedal robots under unknown disturbances</strong>
    <p>R. Beranek, M. Karimi, M. Ahmadi, IEEE/ASME Transactions on Mechatronics.</p>
    <a href="https://ieeexplore.ieee.org/document/9614170" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2021">
    <strong>CPG-based hierarchical locomotion control for modular quadrupedal robots using deep reinforcement learning</strong>
    <p>J. Wang, C. Hu, Y. Zhu, IEEE Robotics and Automation Letters.</p>
    <a href="https://ieeexplore.ieee.org/document/9465716" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2021">
    <strong>Reinforcement learning and neural network-based artificial intelligence control algorithm for self-balancing quadruped robot</strong>
    <p>C. Lee, D. An, Journal of Mechanical Science and Technology.</p>
    <a href="https://link.springer.com/article/10.1007/s12206-020-1230-0" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2022">
    <strong>Reinforcement learning with evolutionary trajectory generator: A general approach for quadrupedal locomotion</strong>
    <p>H. Shi, B. Zhou, H. Zeng, F. Wang, Y. Dong, J. Li, K. Wang, H. Tian, M. Q.-H. Meng, IEEE Robotics and Automation Letters.</p>
    <a href="https://ieeexplore.ieee.org/document/9693519/footnotes#footnotes" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2022">
    <strong>LORM: A novel reinforcement learning framework for biped gait control</strong>
    <p>W. Zhang, Y. Jiang, F. U. D. Farrukh, C. Zhang, D. Zhang, G. Wang, PeerJ Computer Science.</p>
    <a href="https://peerj.com/articles/cs-927/" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2022">
    <strong>Hybrid bipedal locomotion based on reinforcement learning and heuristics</strong>
    <p>Z. Wang, W. Wei, A. Xie, Y. Zhang, J. Wu, Q. Zhu, Micromachines.</p>
    <a href="https://www.mdpi.com/2072-666X/13/10/1688" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2022">
    <strong>Parallel deep reinforcement learning method for gait control of biped robot</strong>
    <p>C. Tao, J. Xue, Z. Zhang, Z. Gao, IEEE Transactions on Circuits and Systems II: Express Briefs.</p>
    <a href="https://ieeexplore.ieee.org/document/9690599" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2023">
    <strong>Adaptive locomotion learning for quadruped robots by combining DRL with a cosine oscillator based rhythm controller</strong>
    <p>X. Zhang, Y. Wu, H. Wang, F. Iida, L. Wang, Applied Sciences.</p>
    <a href="https://www.mdpi.com/2076-3417/13/19/11045" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2023">
    <strong>A multi-agent reinforcement learning method for omnidirectional walking of bipedal robots</strong>
    <p>H. Mou, J. Xue, J. Liu, Z. Feng, Q. Li, J. Zhang, Biomimetics.</p>
    <a href="https://www.mdpi.com/2313-7673/8/8/616" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2024">
    <strong>Visual CPG-RL: Learning central pattern generators for visually-guided quadruped locomotion</strong>
    <p>G. Bellegarda, M. Shafiee, A. Ijspeert, 2024 IEEE International Conference on Robotics and Automation (ICRA).</p>
    <a href="https://ieeexplore.ieee.org/document/10611128" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2024">
    <strong>Robust quadrupedal locomotion via risk-averse policy learning</strong>
    <p>J. Shi, C. Bai, H. He, L. Han, D. Wang, B. Zhao, M. Zhao, X. Li, X. Li, 2024 IEEE International Conference on Robotics and Automation (ICRA).</p>
    <a href="https://ieeexplore.ieee.org/document/10610086" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2024">
    <strong>Meta reinforcement learning of locomotion policy for quadruped robots with motor stuck</strong>
    <p>C. Chen, C. Li, H. Lu, Y. Wang, R. Xiong, IEEE Transactions on Automation Science and Engineering.</p>
    <a href="https://ieeexplore.ieee.org/document/10598356" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2024">
    <strong>Learning advanced locomotion for quadrupedal robots: A distributed multi-agent reinforcement learning framework with Riemannian motion policies</strong>
    <p>Y. Wang, R. Sagawa, Y. Yoshiyasu, Robotics.</p>
    <a href="https://www.mdpi.com/2218-6581/13/6/86" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2024">
    <strong>Reinforcement learning for versatile, dynamic, and robust bipedal locomotion control</strong>
    <p>Z. Li, X. B. Peng, P. Abbeel, S. Levine, G. Berseth, K. Sreenath, The International Journal of Robotics Research.</p>
    <a href="https://journals.sagepub.com/doi/abs/10.1177/02783649241285161" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="" data-id="Robot-Legged" data-year="2024">
    <strong>RL-augmented MPC framework for agile and robust bipedal footstep locomotion planning and control</strong>
    <p>S. H. Bang, C. A. Jové, L. Sentis, 2024 IEEE-RAS 23rd International Conference on Humanoid Robots (Humanoids).</p>
    <a href="https://ieeexplore.ieee.org/document/10769914" target="_blank">[Read more]</a>
</div>
<!-------------------------algorithms ------------------------------>
<div class="col reference-card" data-algorithm="DDPG-PPO-A3C" data-id="Robot-Aerial" data-year="2022">
    <strong>Deep reinforcement learning with corrective feedback for autonomous UAV landing on a mobile platform</strong>
    <p>L. Wu, C. Wang, P. Zhang, C. Wei, Drones.</p>
    <a href="https://www.mdpi.com/2504-446X/6/9/238" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="DDPG-PPO-A3C" data-id="Robot-Aerial" data-year="2023">
    <strong>Single reinforcement learning policy for landing a drone under different UGV velocities and trajectories</strong>
    <p>J. Amendola, L. R. Cenkeramaddi, A. Jha, 2023 11th International Conference on Control, Mechatronics and Automation (ICCMA).</p>
    <a href="https://www.computer.org/csdl/proceedings-article/ises/2023/832400a016/1VuFvoOaIGk" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="DDPG-PPO-A3C" data-id="Robot-Aerial" data-year="2023">
    <strong>Drone landing on moving UGV platform with reinforcement learning based offsets</strong>
    <p>J. Amendola, L. R. Cenkeramaddi, A. Jha, 2023 IEEE International Symposium on Smart Electronic Systems (iSES).</p>
    <a href="https://www.computer.org/csdl/proceedings-article/ises/2023/832400a016/1VuFvoOaIGk" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="DDPG-PPO-A3C" data-id="Robot-Manipulator" data-year="2020">
    <strong>IADRL: Imitation augmented deep reinforcement learning enabled UGV-UAV coalition for tasking in complex environments</strong>
    <p>J. Zhang, Z. Yu, S. Mao, S. C. Periaswamy, J. Patton, X. Xia, IEEE Access.</p>
    <a href="https://ieeexplore.ieee.org/document/9099309" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="DDPG-PPO-A3C" data-id="Robot-Multi-Agent" data-year="2021">
    <strong>Proficiency constrained multi-agent reinforcement learning for environment-adaptive multi UAV-UGV teaming</strong>
    <p>Q. Yu, Z. Shen, Y. Pang, R. Liu, 2021 IEEE 17th International Conference on Automation Science and Engineering (CASE).</p>
    <a href="https://ieeexplore.ieee.org/document/9551457" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="DDPG-PPO-A3C" data-id="Robot-Multi-Agent" data-year="2024">
    <strong>An attention-aware deep reinforcement learning framework for UAV-UGV collaborative route planning</strong>
    <p>M. S. Mondal, S. Ramasamy, J. D. Humann, J. M. Dotterweich, J. P. F. Reddinger, M. A. Childers, P. Bhounsule, 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS).</p>
    <a href="https://pab47.github.io/papers/2024Mondal_attention.pdf" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="DDPG-PPO-A3C" data-id="Robot-Multi-Agent" data-year="2024">
    <strong>Optimizing UAV-UGV coalition operations: A hybrid clustering and multi-agent reinforcement learning approach for path planning in an obstructed environment</strong>
    <p>S. Brotee, F. Kabir, M. A. Razzaque, P. Roy, M. Mamun-Or-Rashid, M. R. Hassan, M. M. Hassan, Ad Hoc Networks.</p>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S1570870524001306" target="_blank">[Read more]</a>
</div>
<div class="col reference-card" data-algorithm="SAC" data-id="Robot-Marine-Aerial" data-year="2023">
    <strong>Cooperative USV–UAV marine search and rescue with visual navigation and reinforcement learning-based control</strong>
    <p>Y. Wang, W. Liu, J. Liu, C. Sun, ISA Transactions.</p>
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0019057823000071" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="PPO" data-id="Robot-" data-year="2021">
    <strong>Bio-inspired rapid escape and tight body flip on an at-scale flapping wing hummingbird robot via reinforcement learning</strong>
    <p>Z. Tu, F. Fei, X. Deng, IEEE Transactions on Robotics.</p>
    <a href="https://ieeexplore.ieee.org/document/9387412" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="DDPG" data-id="" data-year="2023">
    <strong>A multi-agent reinforcement learning method for omnidirectional walking of bipedal robots</strong>
    <p>H. Mou, J. Xue, J. Liu, Z. Feng, Q. Li, J. Zhang, Biomimetics.</p>
    <a href="https://www.mdpi.com/2313-7673/8/8/616" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="DDPG" data-id="" data-year="2022">
    <strong>Design and control of soft biomimetic pangasius fish robot using fin ray effect and reinforcement learning</strong>
    <p>S. M. Youssef, M. Soliman, M. A. Saleh, A. H. Elsayed, A. G. Radwan, Scientific Reports.</p>
    <a href="https://www.nature.com/articles/s41598-022-26179-x" target="_blank">[Read more]</a>
</div>
<div class="col reference-card" data-algorithm="TD3" data-id="" data-year="2023">
    <strong>Residual reinforcement learning for motion control of a bionic exploration robot—robodact</strong>
    <p>T. Zhang, R. Wang, S. Wang, Y. Wang, G. Zheng, M. Tan, IEEE Transactions on Instrumentation and Measurement.</p>
    <a href="https://ieeexplore.ieee.org/document/10143310" target="_blank">[Read more]</a>
</div>

<div class="col reference-card" data-algorithm="TD3" data-id="" data-year="2023">
    <strong>Multiagent-reinforcement learning-based stable path tracking control for a bionic robotic fish with reaction wheel</strong>
    <p>C. Qiu, Z. Wu, J. Wang, M. Tan, J. Yu, IEEE Transactions on Industrial Electronics.</p>
    <a href="https://www.mdpi.com/2075-1702/12/12/902" target="_blank">[Read more]</a>
</div>



                </div>
            </div>
        </div>
    </div>

    <script>

    $(document).ready(function () {
    function filterList() {
        var selectedYear = parseInt($('#year-range').val());
        var selectedAlgorithms = $('#algorithm-select').val().split('-'); // Convert to list
        var selectedRobots = [];

        // Get selected robot types (list)
        $('input[name="Robot"]:checked').each(function () {
            selectedRobots.push($(this).val());
        });

        // Loop through reference cards and apply filters
        $('.reference-card').each(function () {
            var year = parseInt($(this).data('year'));
            var algorithmList = $(this).data('algorithm').split('-'); // Convert to list
            var robotList = $(this).data('id').split('-'); // Convert to list

            // Year filter
            var yearMatch = (year >= selectedYear);

            // Algorithm filter: Match if at least one selected algorithm is in the reference's list
            var algorithmMatch = (selectedAlgorithms.length === 0 || selectedAlgorithms.some(algo => algorithmList.includes(algo)));

            // Robot filter: Match if at least one selected robot type is in the reference's list
            var robotMatch = (selectedRobots.length === 0 || selectedRobots.some(type => robotList.includes(type)));

            console.log("Year:", yearMatch, "Algorithm:", algorithmMatch, "Robot:", robotMatch);

            // Show/hide based on filters
            if (yearMatch && algorithmMatch && robotMatch) {
                $(this).show();
            } else {
                $(this).hide();
            }
        });
    }

    // Attach event listeners
    $('#year-range').on('input', function () {
        $('#selected-year').text(this.value);
        filterList();
    });

    $('#algorithm-select').on('change', filterList);
    $('input[name="Robot"]').on('change', filterList);

    // Initial filtering
    filterList();
});

    </script>
</body>
</html>
